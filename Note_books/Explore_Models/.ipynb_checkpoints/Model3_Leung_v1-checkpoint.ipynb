{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b93318-b204-4321-a902-e019ed05e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09481dd-9747-4663-8591-f470375f62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee37b61a-b150-4bf7-b16b-ca7685251210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd1f830-faa1-449b-99ec-a9dac336049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d23f97-3b91-4868-b566-bed9d7dd76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd905eb-ae20-4c09-a097-d9ced6c6931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a54a87-fb7f-4642-a65e-b2a6c2a6b530",
   "metadata": {},
   "source": [
    "##TUNING INFO \n",
    "\n",
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab795dd-c9bf-4524-abdc-c3b9ba2e5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_LJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803c4a79-77ee-4168-abfe-ac2fe7ba1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>game_id</th>\n",
       "      <th>mp_date</th>\n",
       "      <th>season</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>...</th>\n",
       "      <th>FSh%</th>\n",
       "      <th>FSv%</th>\n",
       "      <th>GDiff</th>\n",
       "      <th>GF%</th>\n",
       "      <th>PDO</th>\n",
       "      <th>PENDiff</th>\n",
       "      <th>SF%</th>\n",
       "      <th>SDiff</th>\n",
       "      <th>Sh%</th>\n",
       "      <th>Sv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.008020e+09</td>\n",
       "      <td>20081005.0</td>\n",
       "      <td>20082009.0</td>\n",
       "      <td>NYR</td>\n",
       "      <td>TBL</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>2.00</td>\n",
       "      <td>33.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.26</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.116144</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.008020e+09</td>\n",
       "      <td>20081005.0</td>\n",
       "      <td>20082009.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>OTT</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.919347</td>\n",
       "      <td>2.919347</td>\n",
       "      <td>1.86</td>\n",
       "      <td>14.28</td>\n",
       "      <td>9.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2.008020e+09</td>\n",
       "      <td>20081011.0</td>\n",
       "      <td>20082009.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MTL</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.916996</td>\n",
       "      <td>-1.953973</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>6.773399</td>\n",
       "      <td>-2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2.008020e+09</td>\n",
       "      <td>20081011.0</td>\n",
       "      <td>20082009.0</td>\n",
       "      <td>OTT</td>\n",
       "      <td>DET</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.736549</td>\n",
       "      <td>2.840909</td>\n",
       "      <td>1.48</td>\n",
       "      <td>14.55</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.65</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>4.272014</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2.008020e+09</td>\n",
       "      <td>20081011.0</td>\n",
       "      <td>20082009.0</td>\n",
       "      <td>NYI</td>\n",
       "      <td>STL</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.858586</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-38.10</td>\n",
       "      <td>-16.69</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-18.881119</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>12439</td>\n",
       "      <td>2.017021e+09</td>\n",
       "      <td>20180407.0</td>\n",
       "      <td>20172018.0</td>\n",
       "      <td>ARI</td>\n",
       "      <td>ANA</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538754</td>\n",
       "      <td>-1.009587</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>-2.49</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.790485</td>\n",
       "      <td>-1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>12440</td>\n",
       "      <td>2.017021e+09</td>\n",
       "      <td>20180407.0</td>\n",
       "      <td>20172018.0</td>\n",
       "      <td>CGY</td>\n",
       "      <td>VGK</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910827</td>\n",
       "      <td>-0.502267</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-8.62</td>\n",
       "      <td>-3.17</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.343425</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>12441</td>\n",
       "      <td>2.017021e+09</td>\n",
       "      <td>20180407.0</td>\n",
       "      <td>20172018.0</td>\n",
       "      <td>EDM</td>\n",
       "      <td>VAN</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451989</td>\n",
       "      <td>-0.233029</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.64</td>\n",
       "      <td>-0.545256</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>12442</td>\n",
       "      <td>2.017021e+09</td>\n",
       "      <td>20180407.0</td>\n",
       "      <td>20172018.0</td>\n",
       "      <td>LAK</td>\n",
       "      <td>DAL</td>\n",
       "      <td>-205.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203981</td>\n",
       "      <td>1.032315</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>0.439817</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>12443</td>\n",
       "      <td>2.017021e+09</td>\n",
       "      <td>20180407.0</td>\n",
       "      <td>20172018.0</td>\n",
       "      <td>SJS</td>\n",
       "      <td>MIN</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866669</td>\n",
       "      <td>-0.089346</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.57</td>\n",
       "      <td>-0.815267</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10385 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       game_id     mp_date      season home_team away_team  \\\n",
       "0               2  2.008020e+09  20081005.0  20082009.0       NYR       TBL   \n",
       "1               3  2.008020e+09  20081005.0  20082009.0       PIT       OTT   \n",
       "2              15  2.008020e+09  20081011.0  20082009.0       TOR       MTL   \n",
       "3              16  2.008020e+09  20081011.0  20082009.0       OTT       DET   \n",
       "4              17  2.008020e+09  20081011.0  20082009.0       NYI       STL   \n",
       "...           ...           ...         ...         ...       ...       ...   \n",
       "10380       12439  2.017021e+09  20180407.0  20172018.0       ARI       ANA   \n",
       "10381       12440  2.017021e+09  20180407.0  20172018.0       CGY       VGK   \n",
       "10382       12441  2.017021e+09  20180407.0  20172018.0       EDM       VAN   \n",
       "10383       12442  2.017021e+09  20180407.0  20172018.0       LAK       DAL   \n",
       "10384       12443  2.017021e+09  20180407.0  20172018.0       SJS       MIN   \n",
       "\n",
       "       home_odds  away_odds  home_goals  away_goals  ...       FSh%      FSv%  \\\n",
       "0         -125.0      105.0         2.0         1.0  ...   0.547778  0.547778   \n",
       "1         -110.0     -110.0         1.0         3.0  ...   2.919347  2.919347   \n",
       "2          110.0     -130.0         1.0         6.0  ...   6.916996 -1.953973   \n",
       "3          115.0     -135.0         2.0         3.0  ...   2.736549  2.840909   \n",
       "4         -125.0      105.0         5.0         2.0  ... -10.858586  0.366300   \n",
       "...          ...        ...         ...         ...  ...        ...       ...   \n",
       "10380      130.0     -150.0         0.0         3.0  ...  -0.538754 -1.009587   \n",
       "10381      108.0     -128.0         7.0         1.0  ...  -1.910827 -0.502267   \n",
       "10382     -183.0      163.0         2.0         2.0  ...  -0.451989 -0.233029   \n",
       "10383     -205.0      175.0         2.0         4.0  ...   0.203981  1.032315   \n",
       "10384     -175.0      155.0         3.0         6.0  ...  -0.866669 -0.089346   \n",
       "\n",
       "       GDiff    GF%    PDO  PENDiff    SF%  SDiff        Sh%    Sv  \n",
       "0       2.00  33.34   0.24      6.0  32.26  40.00   0.116144  0.12  \n",
       "1       1.86  14.28   9.52      2.0  -7.70  -9.30   4.761905  4.76  \n",
       "2       1.00  10.00   4.15      0.0   0.19  -2.00   6.773399 -2.63  \n",
       "3       1.48  14.55   6.42     -5.0  -5.65  -7.52   4.272014  2.14  \n",
       "4      -4.00 -38.10 -16.69     -1.0  -2.73  -3.00 -18.881119  2.19  \n",
       "...      ...    ...    ...      ...    ...    ...        ...   ...  \n",
       "10380  -0.74  -6.80  -2.49     76.0   0.34   0.47  -0.790485 -1.70  \n",
       "10381  -0.98  -8.62  -3.17    -22.0   0.29   0.42  -2.343425 -0.83  \n",
       "10382   0.08   0.88  -0.72      0.0   2.91   3.64  -0.545256 -0.18  \n",
       "10383   0.36   3.49   1.72     -1.0  -1.46  -1.76   0.439817  1.28  \n",
       "10384   0.07   0.68  -0.84     58.0   2.87   3.57  -0.815267 -0.02  \n",
       "\n",
       "[10385 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9ae08-71a1-45e1-aeb8-4d710ee856a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_L[season != 20182019.iloc[:, 10:] #features test-train\n",
    "Y = data_L[season != 20182019.iloc[:, :10]  #targets\n",
    "y = Y['won']\n",
    "\n",
    "X_18 = data_L[season == 20182019.iloc[:, 10:] #features final test\n",
    "Y_18 = data_L[season == 20182019.iloc[:, :10]  #targets\n",
    "y_18 = Y_18['won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d1c92-3ca5-447e-a9da-9393db3b9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6992da-3597-4ffc-9d72-5f89df4ddfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##handy code from Leung\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "def train_predictproba(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    display(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65857f1c-005a-411c-b8d2-2f1430170d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = SVC(random_state = 43, kernel = 'rbf')\n",
    "clf_C = xgb.XGBClassifier(seed = 44)\n",
    "clf_D = SVC(probability=True)\n",
    "\n",
    "train_predict(clf_A, x_train, y_train, x_test, y_test)\n",
    "print('')\n",
    "train_predict(clf_B, x_train, y_train, x_test, y_test)\n",
    "print('')\n",
    "train_predict(clf_C, x_train, y_train, x_test, y_test)\n",
    "print('')\n",
    "train_predict(clf_D, x_train, y_train, x_test, y_test)\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
