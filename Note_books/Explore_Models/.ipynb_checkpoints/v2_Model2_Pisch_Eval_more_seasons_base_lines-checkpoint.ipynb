{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b210964-63eb-4766-bac4-d91ee0dfbfe1",
   "metadata": {},
   "source": [
    "##I am splitting v3_Clean_model_add_Pis_feat.ipynb into 2 notebooks \n",
    "\n",
    "-this one on modelling and \n",
    "\n",
    "-another one on creating stats data set (just Pisch for now)\n",
    "v1_stats_tools_Pish.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a81d7-900b-46e1-9c38-4f1c9cdb3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "##part 1\n",
    "##use models with default\n",
    "##use data set with H/A +1, -1\n",
    "##do full window for now\n",
    "\n",
    "##next:\n",
    "##check if just excluding first 10 days helps (chaotic)\n",
    "##check if different windows help\n",
    "\n",
    "##next\n",
    "## can try tuning (for loops by hand, or ... use grid_search (use ML mastery code))\n",
    "##-I think tuning will be faster ... just do by hand ... loop over the possible things \n",
    "##-ONE for loop over i = (a,b,c,d)... for each model i[0]\n",
    "\n",
    "##Orrr can try adding features ... here we have to worry about:\n",
    "##-adding basic features eg pp, and correct fo%\n",
    "##-scaling numericals\n",
    "##-dummy vars for categoricals (are there any?) besides H/A\n",
    "##-num_windows and which lengths for moving avgs\n",
    "##-filtering the features for increasing complexity inteligently\n",
    "##-There is a dicotemy: \n",
    "##(a)use H/A + numerics or  ... here I think it can be made more like time-series\n",
    "##(b) just use mumerics (moving avg) ... here I think the order of the games is not important (note Leung did this, and random train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "778fca46-90be-4c9f-a057-1e41ffea0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "##couple evaluation functions ##removed model_name as variable\n",
    "def evaluate_binary_classification(y_test, y_pred, y_proba=None, graph = False):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    #try:\n",
    "    if y_proba != None:\n",
    "        rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        rocauc_score = \"no roc\"\n",
    "    #except: \n",
    "    #    pass     \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if graph == True:\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f'{model_name}', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1 score: \", f1)\n",
    "    print(\"rocauc: \", rocauc_score)\n",
    "    print(cm)\n",
    "    #return accuracy, precision, recall, f1, rocauc_score\n",
    "\n",
    "def evaluate_regression(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"mae\", mae)\n",
    "    print(\"mse\", mse)\n",
    "    print('r2', r2)\n",
    "    \n",
    "##display null values\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5d24d58a-39a7-44ed-95da-fbbeaaffbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the odds eg -200 is the favorite, 140 is underdog and says fav wins \n",
    "\n",
    "def fav_win(x):\n",
    "    if x <=0:\n",
    "        return 1\n",
    "    if x>0:\n",
    "        return 0\n",
    "    \n",
    "v_fav_win = np.vectorize(fav_win)\n",
    "\n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18af7514-a756-444a-bd2f-4de970ba321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []   \n",
    "    \n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        \n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'goal_difference' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'goal_difference' ]\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results_dic['model_name'].append(model_name)\n",
    "        results_dic['date'].append(dates[i])\n",
    "    \n",
    "        results_dic['mae'].append(mae)\n",
    "        results_dic['mse'].append(mse)\n",
    "        results_dic['r2'].append(r2)\n",
    "        \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e7ec9a6-f01d-47c0-b2d1-02902750ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic ={}\n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['accuracy'] = []\n",
    "    results_dic['f1_score'] = []\n",
    "\n",
    "    #results_dic['precision'] = []\n",
    "  #  results_dic['recall'] = []\n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'won' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'won' ]\n",
    "    \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #recision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "        #recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred) #, average = None)\n",
    "            \n",
    "        results_dic['model_name'].append(model_name)  #append same model name every iter so same length as others\n",
    "        results_dic['date'].append(dates[i])\n",
    "                          \n",
    "        results_dic['accuracy'].append(accuracy)\n",
    "        results_dic['f1_score'].append(f1)\n",
    "        #results_dic['precision'].append(precision)\n",
    "        #results_dic['recall'].append(recall)\n",
    "    results_dic['model_name'].append('model_name'+'_avg')  #append same model name every iter so same length as others\n",
    "    results_dic['date'].append('average')\n",
    "    results_dic['accuracy'].append(round(np.mean(np.array(results_dic['accuracy'])), 2) ) \n",
    "    results_dic['f1_score'].append(round(np.mean(np.array(results_dic['f1_score'])), 2) ) \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c935eaa1-b629-406d-94f1-147c6daed626",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbaf7e-46af-4a63-9a9c-bbe35291577d",
   "metadata": {},
   "source": [
    "##TUNING INFO \n",
    "\n",
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcbb7207-4cc5-47b0-aa6b-7ba80d933695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC(kernel = 'rbf')\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=5, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b36d368b-45fc-44c1-a5ff-579fea4fe286",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "\n",
    "file_path_12 = '/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_v2_20122013.csv'\n",
    "data_dic[20122013] = pd.read_csv(file_path_12)\n",
    "\n",
    "for season in [20152016, 20162017, 20172018, 20182019]:   \n",
    "    \n",
    "    file_path_seas = '/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/'+'data_dummies_Pis_xg_Corsi_v3_'+str(season)+'.csv'\n",
    "    data_dic[season] = pd.read_csv(file_path_seas)\n",
    " # data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_v2_20122013.csv\n",
    "#data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_xg_Corsi_v3_20152016.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "38fe6f08-f93a-4e4d-a225-f4e4cf4160d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_12 = data_dic[20122013].copy()  \n",
    "data_15 = data_dic[20152016].copy()\n",
    "data_16  = data_dic[20162017].copy()\n",
    "data_17 = data_dic[20172018].copy()\n",
    "data_18 = data_dic[20182019].copy()\n",
    "data_15_17 = pd.concat([data_15,data_16])\n",
    "data_17_19 = pd.concat([data_17,data_18])\n",
    "#Note Bene\n",
    "data_12.rename(columns ={'win%':'win%_cumul'}, inplace = True)\n",
    "data_12.rename(columns ={'last_10_games_win%' :'win%_last_10_games'}, inplace = True)\n",
    "#(1230, 50)\n",
    "#(1230, 50)\n",
    "#(1271, 51) Vegas, baby\n",
    "#(1271, 51)'win%_last_10_games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e289286b-800d-4871-9e70-8d23a6373f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'won', 'goal_difference', 'Open', 'game_id', 'full_date',\n",
       "       'date', 'ANA', 'ARI', 'BOS', 'BUF', 'CAR', 'CBJ', 'CGY', 'CHI', 'COL',\n",
       "       'DAL', 'DET', 'EDM', 'FLA', 'LAK', 'MIN', 'MTL', 'NJD', 'NSH', 'NYI',\n",
       "       'NYR', 'OTT', 'PHI', 'PIT', 'SJS', 'STL', 'TBL', 'TOR', 'VAN', 'WPG',\n",
       "       'WSH', 'goalsAgainst_cumul_sum', 'goalsFor_cumul_sum',\n",
       "       'goalsDiff_cumul_sum', 'goalsFor%_cumul_avg', 'pp%_cumul_avg',\n",
       "       'pk%_cumul_avg', 'sh%_cumul_avg', 'sv%_cumul_avg', 'PDO_cumul_avg',\n",
       "       'fenwickPercentage_cumul_avg', 'win%_last_10_games', 'win%_cumul'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "43d1417b-2139-46ca-a398-e65d0d403a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 49)\n",
      "(1230, 50)\n",
      "(1230, 50)\n",
      "(1271, 51)\n",
      "(1271, 51)\n"
     ]
    }
   ],
   "source": [
    "for season in [20122013,20152016, 20162017, 20172018, 20182019]:    \n",
    "    print(data_dic[season].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "399124c2-be5d-4291-a3dc-67a277ea9cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>won</th>\n",
       "      <th>goal_difference</th>\n",
       "      <th>Open</th>\n",
       "      <th>game_id</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date</th>\n",
       "      <th>ANA</th>\n",
       "      <th>ARI</th>\n",
       "      <th>BOS</th>\n",
       "      <th>...</th>\n",
       "      <th>goalsDiff_cumul_sum</th>\n",
       "      <th>goalsFor%_cumul_avg</th>\n",
       "      <th>pp%_cumul_avg</th>\n",
       "      <th>pk%_cumul_avg</th>\n",
       "      <th>sh%_cumul_avg</th>\n",
       "      <th>sv%_cumul_avg</th>\n",
       "      <th>PDO_cumul_avg</th>\n",
       "      <th>fenwickPercentage_cumul_avg</th>\n",
       "      <th>last_10_games_win%</th>\n",
       "      <th>win%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-105</td>\n",
       "      <td>2012020001</td>\n",
       "      <td>20130119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>2012020002</td>\n",
       "      <td>20130119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-130</td>\n",
       "      <td>2012020003</td>\n",
       "      <td>20130119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-120</td>\n",
       "      <td>2012020004</td>\n",
       "      <td>20130119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-135</td>\n",
       "      <td>2012020005</td>\n",
       "      <td>20130119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2012020717</td>\n",
       "      <td>20130427</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-0.035630</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>-0.011179</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>-0.064266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2012020718</td>\n",
       "      <td>20130427</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-0.115817</td>\n",
       "      <td>0.043558</td>\n",
       "      <td>-0.022948</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>-0.004858</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>-0.065536</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-155</td>\n",
       "      <td>2012020719</td>\n",
       "      <td>20130427</td>\n",
       "      <td>427</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>-0.018613</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.212766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-150</td>\n",
       "      <td>2012020720</td>\n",
       "      <td>20130427</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>-0.038180</td>\n",
       "      <td>0.021633</td>\n",
       "      <td>-0.019687</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-230</td>\n",
       "      <td>2012020624</td>\n",
       "      <td>20130428</td>\n",
       "      <td>428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.076134</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>-0.014843</td>\n",
       "      <td>0.011085</td>\n",
       "      <td>-0.007410</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  won  goal_difference  Open     game_id  full_date  date  ANA  \\\n",
       "0             0    0             -2.0  -105  2012020001   20130119   119    0   \n",
       "1             1    0             -3.0  -120  2012020002   20130119   119    0   \n",
       "2             2    0             -3.0  -130  2012020003   20130119   119    0   \n",
       "3             3    1              2.0  -120  2012020004   20130119   119    0   \n",
       "4             4    0             -1.0  -135  2012020005   20130119   119    0   \n",
       "..          ...  ...              ...   ...         ...        ...   ...  ...   \n",
       "715         715    0             -3.0   105  2012020717   20130427   427    0   \n",
       "716         716    1              5.0   105  2012020718   20130427   427    0   \n",
       "717         717    0             -2.0  -155  2012020719   20130427   427   -1   \n",
       "718         718    1              1.0  -150  2012020720   20130427   427    0   \n",
       "719         719    0             -2.0  -230  2012020624   20130428   428    0   \n",
       "\n",
       "     ARI  BOS  ...  goalsDiff_cumul_sum  goalsFor%_cumul_avg  pp%_cumul_avg  \\\n",
       "0      0    0  ...                  NaN                  NaN            NaN   \n",
       "1      0    0  ...                  NaN                  NaN            NaN   \n",
       "2      0    0  ...                  NaN                  NaN            NaN   \n",
       "3      0   -1  ...                  NaN                  NaN            NaN   \n",
       "4      0    0  ...                  NaN                  NaN            NaN   \n",
       "..   ...  ...  ...                  ...                  ...            ...   \n",
       "715    0    0  ...                -19.0            -0.035630      -0.007143   \n",
       "716    0    0  ...                -26.0            -0.115817       0.043558   \n",
       "717    1    0  ...                 27.0             0.069791       0.065907   \n",
       "718    0    0  ...                 12.0             0.029841      -0.001672   \n",
       "719    0   -1  ...                 13.0             0.076134       0.009929   \n",
       "\n",
       "     pk%_cumul_avg  sh%_cumul_avg  sv%_cumul_avg  PDO_cumul_avg  \\\n",
       "0              NaN            NaN            NaN            NaN   \n",
       "1              NaN            NaN            NaN            NaN   \n",
       "2              NaN            NaN            NaN            NaN   \n",
       "3              NaN            NaN            NaN            NaN   \n",
       "4              NaN            NaN            NaN            NaN   \n",
       "..             ...            ...            ...            ...   \n",
       "715      -0.042334       0.015628      -0.011179       0.004450   \n",
       "716      -0.022948      -0.000730      -0.004858      -0.005587   \n",
       "717      -0.002668       0.022931       0.002161       0.025092   \n",
       "718      -0.038180       0.021633      -0.019687       0.001946   \n",
       "719      -0.014843       0.011085      -0.007410       0.003675   \n",
       "\n",
       "     fenwickPercentage_cumul_avg  last_10_games_win%      win%  \n",
       "0                            NaN                 NaN       NaN  \n",
       "1                            NaN                 NaN       NaN  \n",
       "2                            NaN                 NaN       NaN  \n",
       "3                            NaN                 NaN       NaN  \n",
       "4                            NaN                 NaN       NaN  \n",
       "..                           ...                 ...       ...  \n",
       "715                    -0.064266                 0.0 -0.021277  \n",
       "716                    -0.065536                -0.4 -0.170213  \n",
       "717                    -0.018613                 0.1  0.212766  \n",
       "718                     0.023549                 0.0  0.021277  \n",
       "719                     0.010809                -0.1  0.085106  \n",
       "\n",
       "[720 rows x 49 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "229885f1-8840-47a5-8691-374ed5cc0f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>game_id</th>\n",
       "      <th>full_date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>Open</th>\n",
       "      <th>goal_difference</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016020001</td>\n",
       "      <td>20161012</td>\n",
       "      <td>OTT</td>\n",
       "      <td>TOR</td>\n",
       "      <td>-134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016020002</td>\n",
       "      <td>20161012</td>\n",
       "      <td>CHI</td>\n",
       "      <td>STL</td>\n",
       "      <td>-128</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016020003</td>\n",
       "      <td>20161012</td>\n",
       "      <td>EDM</td>\n",
       "      <td>CGY</td>\n",
       "      <td>-128</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016020004</td>\n",
       "      <td>20161012</td>\n",
       "      <td>SJS</td>\n",
       "      <td>LAK</td>\n",
       "      <td>-124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016020008</td>\n",
       "      <td>20161013</td>\n",
       "      <td>CBJ</td>\n",
       "      <td>BOS</td>\n",
       "      <td>-115</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2016020005</td>\n",
       "      <td>20161013</td>\n",
       "      <td>BUF</td>\n",
       "      <td>MTL</td>\n",
       "      <td>-115</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2016020006</td>\n",
       "      <td>20161013</td>\n",
       "      <td>NYR</td>\n",
       "      <td>NYI</td>\n",
       "      <td>-135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2016020009</td>\n",
       "      <td>20161013</td>\n",
       "      <td>TBL</td>\n",
       "      <td>DET</td>\n",
       "      <td>-170</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2016020010</td>\n",
       "      <td>20161013</td>\n",
       "      <td>FLA</td>\n",
       "      <td>NJD</td>\n",
       "      <td>-145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2016020012</td>\n",
       "      <td>20161013</td>\n",
       "      <td>WPG</td>\n",
       "      <td>CAR</td>\n",
       "      <td>-140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     game_id  full_date home_team away_team  Open  \\\n",
       "0           0  2016020001   20161012       OTT       TOR  -134   \n",
       "1           1  2016020002   20161012       CHI       STL  -128   \n",
       "2           2  2016020003   20161012       EDM       CGY  -128   \n",
       "3           3  2016020004   20161012       SJS       LAK  -124   \n",
       "4           4  2016020008   20161013       CBJ       BOS  -115   \n",
       "5           5  2016020005   20161013       BUF       MTL  -115   \n",
       "6           6  2016020006   20161013       NYR       NYI  -135   \n",
       "7           7  2016020009   20161013       TBL       DET  -170   \n",
       "8           8  2016020010   20161013       FLA       NJD  -145   \n",
       "9           9  2016020012   20161013       WPG       CAR  -140   \n",
       "\n",
       "   goal_difference  won  \n",
       "0              1.0    1  \n",
       "1             -3.0    0  \n",
       "2              3.0    1  \n",
       "3              1.0    1  \n",
       "4             -3.0    0  \n",
       "5             -3.0    0  \n",
       "6              2.0    1  \n",
       "7              2.0    1  \n",
       "8              1.0    1  \n",
       "9              1.0    1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_16.iloc[:10, :8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d8cf071-2df8-41a3-8d37-cb37b9e3053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANA</th>\n",
       "      <th>ARI</th>\n",
       "      <th>BOS</th>\n",
       "      <th>BUF</th>\n",
       "      <th>CAR</th>\n",
       "      <th>CBJ</th>\n",
       "      <th>CGY</th>\n",
       "      <th>CHI</th>\n",
       "      <th>COL</th>\n",
       "      <th>DAL</th>\n",
       "      <th>...</th>\n",
       "      <th>goalsDiff_cumul_sum</th>\n",
       "      <th>goalsFor%_cumul_avg</th>\n",
       "      <th>pp%_cumul_avg</th>\n",
       "      <th>pk%_cumul_avg</th>\n",
       "      <th>sh%_cumul_avg</th>\n",
       "      <th>sv%_cumul_avg</th>\n",
       "      <th>PDO_cumul_avg</th>\n",
       "      <th>fenwickPercentage_cumul_avg</th>\n",
       "      <th>last_10_games_win%</th>\n",
       "      <th>win%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANA  ARI  BOS  BUF  CAR  CBJ  CGY  CHI  COL  DAL  ...  goalsDiff_cumul_sum  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "2    0    0    0    0    0    0    0    1    0    0  ...                  NaN   \n",
       "3    0    0   -1    0    0    0    0    0    0    0  ...                  NaN   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "5    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "6    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "7    0    0    0    0    1    0    0    0    0    0  ...                  NaN   \n",
       "8    0    0    0    0    0    0    0    0    0    0  ...                  NaN   \n",
       "9    0    0    0    0    0    1    0    0    0    0  ...                  NaN   \n",
       "\n",
       "   goalsFor%_cumul_avg  pp%_cumul_avg  pk%_cumul_avg  sh%_cumul_avg  \\\n",
       "0                  NaN            NaN            NaN            NaN   \n",
       "1                  NaN            NaN            NaN            NaN   \n",
       "2                  NaN            NaN            NaN            NaN   \n",
       "3                  NaN            NaN            NaN            NaN   \n",
       "4                  NaN            NaN            NaN            NaN   \n",
       "5                  NaN            NaN            NaN            NaN   \n",
       "6                  NaN            NaN            NaN            NaN   \n",
       "7                  NaN            NaN            NaN            NaN   \n",
       "8                  NaN            NaN            NaN            NaN   \n",
       "9                  NaN            NaN            NaN            NaN   \n",
       "\n",
       "   sv%_cumul_avg  PDO_cumul_avg  fenwickPercentage_cumul_avg  \\\n",
       "0            NaN            NaN                          NaN   \n",
       "1            NaN            NaN                          NaN   \n",
       "2            NaN            NaN                          NaN   \n",
       "3            NaN            NaN                          NaN   \n",
       "4            NaN            NaN                          NaN   \n",
       "5            NaN            NaN                          NaN   \n",
       "6            NaN            NaN                          NaN   \n",
       "7            NaN            NaN                          NaN   \n",
       "8            NaN            NaN                          NaN   \n",
       "9            NaN            NaN                          NaN   \n",
       "\n",
       "   last_10_games_win%  win%  \n",
       "0                 NaN   NaN  \n",
       "1                 NaN   NaN  \n",
       "2                 NaN   NaN  \n",
       "3                 NaN   NaN  \n",
       "4                 NaN   NaN  \n",
       "5                 NaN   NaN  \n",
       "6                 NaN   NaN  \n",
       "7                 NaN   NaN  \n",
       "8                 NaN   NaN  \n",
       "9                 NaN   NaN  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_12.iloc[:10,7:]  ##columns are all safe ... \n",
    "#win%_cumul HAS to be previous day (NOT including day of ... o/w model can inspect \n",
    "#which teams win% went up and which ... actually kinda tough bec it's difference )\n",
    "##anyway I checked in v1_stats 'SJS' ... that win% = win%_cumul is *strictly* the previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d3ad79d-3202-44d4-8436-b6523d347b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', 'goalsDiff_cumul_sum',\n",
       "       'goalsFor%_cumul_avg', 'pp%_cumul_avg', 'pk%_cumul_avg',\n",
       "       'sh%_cumul_avg', 'sv%_cumul_avg', 'PDO_cumul_avg',\n",
       "       'fenwickPercentage_cumul_avg', 'win%_last_10_games', 'win%_cumul'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_scale = list(data_15.iloc[:5, 38:].columns)\n",
    "data_15.iloc[:5, 38:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eeea4a3b-2293-4484-8239-1294f6228e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'game_id', 'full_date', 'home_team', 'away_team', 'Open',\n",
       "       'goal_difference', 'won'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_target = list(data_15.iloc[:5, :8].columns)\n",
    "data_15.iloc[:5, :8].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8826372f-b7a0-40c7-ac29-0416de7e4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_12 = data_12.iloc[:,7:].copy() \n",
    "X_15 = data_15.drop(columns = columns_target ).copy()\n",
    "X_16 = data_16.drop(columns = columns_target ).copy()\n",
    "X_17 = data_17.drop(columns = columns_target ).copy()\n",
    "X_18 = data_18.drop(columns = columns_target ).copy()\n",
    "y_12 = data_12.iloc[:,:7].copy() \n",
    "y_15 = data_15.loc[:, columns_target ].copy()\n",
    "y_16 = data_16.loc[:, columns_target ].copy()\n",
    "y_17 = data_17.loc[:, columns_target ].copy()\n",
    "y_18 = data_18.loc[:, columns_target ].copy()\n",
    "list_X = [X_12, X_15,X_16, X_17, X_18]\n",
    "list_y = [y_12, y_15, y_16,y_17, y_18 ]\n",
    "list_Xy = zip(list_X, list_y)\n",
    "list_data = [data_12, data_15, data_16, data_17, data_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a3584b4f-b9de-4280-bcc8-a8031a24851e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f861a-a646-432f-bb32-28ec219123b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude 1st couple dates of season to get rid of nan values ... might want to do more too... \n",
    "\n",
    "sorted(set(data['full_date']))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781f6b4-4942-4074-b0ec-c76d6e867400",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(data['full_date'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4f528-8e7a-4ac4-8a94-fcab4e24e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783bf72-2c13-4c90-b664-f0ae4a1dd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[(data['full_date'] >=  20130121), :].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6583c-abfd-454a-bd01-3d32e874c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.iloc[:, :7].copy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b59a2-921c-4039-ace4-1a87a7ea41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:, 7:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1b7bb-473b-48a6-a3d3-62f8096d2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_regr = y['goal_difference'].copy()\n",
    "y_win = y['won'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ddbe65a-0e05-4883-a3ac-4d863e9fe234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_12.shape\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b95991df-ed95-4dc7-9695-7cfce5006d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012020001 0.5680555555555555 0.7245349867139061\n",
      "2015020001 0.5292682926829269 0.6921850079744817\n",
      "2016020001 0.5593495934959349 0.7174139728884255\n",
      "2017020001 0.5633359559402046 0.7206844489179668\n",
      "2018020001 0.5365853658536586 0.6984126984126985\n"
     ]
    }
   ],
   "source": [
    "##some baselines \n",
    "\n",
    "##predict home teams wins (always 1) why is f1 so good eek\n",
    "\n",
    "for y in list_y:\n",
    "    num_rows = y.shape[0]\n",
    "    y_pred_ones = np.ones(num_rows, dtype=int)\n",
    "    y_test = y.loc[:, 'won'].copy()\n",
    "    acc = accuracy_score(y_test, y_pred_ones)\n",
    "    f1 = f1_score(y_test,y_pred_ones)\n",
    "    print(y.loc[0, 'game_id'], acc, f1)\n",
    "    #evaluate_binary_classification(y_test, y_pred_ones, y_proba=None, graph = False)\n",
    "    \n",
    "##woof!   53% to 56%    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f168448f-747b-4394-914b-2cf4ccd16dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012020001 0.5819444444444445 0.7069133398247321\n",
      "2015020001 0.5780487804878048 0.6782393056416615\n",
      "2016020001 0.5886178861788618 0.6973684210526316\n",
      "2017020001 0.5916601101494886 0.7046101309049517\n",
      "2018020001 0.5767112509834775 0.6739393939393938\n"
     ]
    }
   ],
   "source": [
    "##some baselines \n",
    "\n",
    "##predict betting favourite (this is basically someone else's algo)\n",
    "\n",
    "for y in list_y:\n",
    "    \n",
    "    y_pred_fav = v_fav_win(y.loc[:,'Open'])\n",
    "    y_test = y.loc[:, 'won'].copy()\n",
    "    acc = accuracy_score(y_test, y_pred_fav)\n",
    "    f1 = f1_score(y_test,y_pred_fav)\n",
    "    print(y.loc[0, 'game_id'], acc, f1)\n",
    "    #evaluate_binary_classification(y_test,y_pred_fav)\n",
    "    \n",
    "##woof!   53% to 56%    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e647e7da-5485-4b9d-bca7-5e8d8809554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19      True\n",
       "20     False\n",
       "21      True\n",
       "22      True\n",
       "23     False\n",
       "       ...  \n",
       "715     True\n",
       "716    False\n",
       "717    False\n",
       "718     True\n",
       "719    False\n",
       "Name: won, Length: 701, dtype: bool"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = (y_12['full_date'] >= y_12['full_date'][0]+2) #removes first 2 days of season\n",
    "y_12.loc[filter, 'won']==v_make_win(X_12.loc[filter, 'win%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "47da1c1c-c052-4306-be1c-8ffb1f268a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ANA', 'ARI', 'BOS', 'BUF', 'CAR', 'CBJ', 'CGY', 'CHI', 'COL', 'DAL',\n",
       "       'DET', 'EDM', 'FLA', 'LAK', 'MIN', 'MTL', 'NJD', 'NSH', 'NYI', 'NYR',\n",
       "       'OTT', 'PHI', 'PIT', 'SJS', 'STL', 'TBL', 'TOR', 'VAN', 'WPG', 'WSH',\n",
       "       'goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', 'goalsDiff_cumul_sum',\n",
       "       'goalsFor%_cumul_avg', 'pp%_cumul_avg', 'pk%_cumul_avg',\n",
       "       'sh%_cumul_avg', 'sv%_cumul_avg', 'PDO_cumul_avg',\n",
       "       'fenwickPercentage_cumul_avg', 'win%_last_10_games', 'win%_cumul'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_15.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "002a9e99-394c-49bb-8658-c61394167b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5048387096774194\n",
      "precision:  0.5738255033557047\n",
      "recall:  0.48717948717948717\n",
      "f1 score:  0.5269645608628659\n",
      "rocauc:  no roc\n",
      "[[142 127]\n",
      " [180 171]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b4abebed-c1d0-4ee4-8f40-b41cb6d60f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015020001 0.5048387096774194 0.5269645608628659\n",
      "2015020001 0.5150442477876106 0.5283993115318416\n",
      "2015020001 0.5256637168141592 0.5363321799307958\n",
      "2015020001 0.5653287788215201 0.5891848264729621\n",
      "2015020001 0.5149444918872759 0.5250836120401337\n"
     ]
    }
   ],
   "source": [
    "##predict team with higher win% or last win%_last_10\n",
    "for data in list_data:\n",
    "    Y = data.iloc[100:,:].copy()\n",
    "    y_pred =v_make_win(Y.loc[:,'win%_cumul']).copy()\n",
    "    y_test = Y.loc[:, 'won'].copy()\n",
    "    #evaluate_binary_classification(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(y.loc[0, 'game_id'], acc, f1)\n",
    " ##pretty trash 51% except one 56%       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "da043003-3891-4a88-a7d2-9e78a82e5f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015020001 0.5080645161290323 0.49752883031301476\n",
      "2015020001 0.5088495575221239 0.4837209302325582\n",
      "2015020001 0.5053097345132743 0.4857405703771849\n",
      "2015020001 0.5072587532023911 0.5139005897219882\n",
      "2015020001 0.5149444918872759 0.4892086330935252\n"
     ]
    }
   ],
   "source": [
    "##predict team with higher win% or last win%_last_10\n",
    "for data in list_data:\n",
    "    Y = data.iloc[100:,:].copy()\n",
    "    y_pred =v_make_win(Y.loc[:,'win%_last_10_games']).copy()\n",
    "    y_test = Y.loc[:, 'won'].copy()\n",
    "    #evaluate_binary_classification(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(y.loc[0, 'game_id'], acc, f1)\n",
    " ##pretty trash 51% except one 56%       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0a1b3-33c7-45a6-b2ab-4afb91f7fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (y['full_date'] >= y['full_date'][0]+2) #removes first 2 days of season\n",
    "    y_pred =v_make_win(X.loc[filter,'win%']).copy()\n",
    "    y_test = y.loc[filter, 'won'].copy()\n",
    "    evaluate_binary_classification(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76397d24-e8e9-4811-b795-a81108bf5bb6",
   "metadata": {},
   "source": [
    "End of baselines ... on to modelling ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "53f2cc86-387d-42a1-8f0d-7299a35c8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "586a5515-3122-4f45-898d-4aa144910e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scaler = StandardScaler()\n",
    "mm_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe1314-e15e-415a-bb5a-d0bde3acf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##classifiers split about half way\n",
    "for model in [lrc,  gnb, lgr, svc,  rfc, bc, gbc, xgbc]:\n",
    "    X_15.loc[:300 :]\n",
    "    model.fit(X.iloc[:300 :], y_win[:300])\n",
    "    y_pred = model.predict(X.iloc[300:, :])\n",
    "    y_test = y_win[300:].copy()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(model, acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fee00-a8f0-44ce-a6d6-ca1d06531e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok pretty pretty good start ... logistic and ridgec 0.5835. (they are identical .. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95e803-77c9-47f3-a160-4bb2b5787882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6ad2b-c29e-4af4-a25c-6fdb32746a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d68b54-673f-4fb0-aaa8-7770af1d815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgr\n",
    "##quick checks \n",
    "for d in range(20,660,20):\n",
    "    pipe_lgr.fit(X.iloc[:d :], y_win[:d])\n",
    "    model.fit(X.iloc[:d :], y_win[:d])\n",
    "    #y_pred1 = pipe_lgr.predict(X.iloc[d:, :])\n",
    "    y_pred = model.predict(X.iloc[d:, :])\n",
    "    y_test = y_win[d:].copy()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(d, model, acc, f1)\n",
    "    \n",
    "    #print(d, pipe_lgr, acc1, f11)\n",
    "    #print(d, lgr, acc2, f12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bd45e-bd4c-4f88-9632-a87cd5e6454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##example from stack overflow how to do multiple variable line graphs ... \n",
    "\n",
    "num_rows = 20\n",
    "years = list(range(1990, 1990 + num_rows))\n",
    "data_preproc = pd.DataFrame({\n",
    "    'Year': years, \n",
    "    'A': np.random.randn(num_rows).cumsum(),\n",
    "    'B': np.random.randn(num_rows).cumsum(),\n",
    "    'C': np.random.randn(num_rows).cumsum(),\n",
    "    'D': np.random.randn(num_rows).cumsum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe96720-1917-4326-9026-37776ebcf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preproc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdf8fb-a91d-4473-b0ea-e428b2859688",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(data_preproc, ['Year'])[0:3]  ##seaborn  WHY? would you do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e32044-aa37-4fa3-80df-59d8a38b18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_theme(style='darkgrid', context='talk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75cadf-54b7-4931-8ad9-92ccfedd2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='Year', y='value', hue='variable', \n",
    "             data=pd.melt(data_preproc, ['Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689b6c7-39d0-4c4c-a8f2-1640ae447186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model_results(lgr, model_name ='logistic', X, dates, step, window_size, prediction_size, drop_first_k_days = 0): "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
