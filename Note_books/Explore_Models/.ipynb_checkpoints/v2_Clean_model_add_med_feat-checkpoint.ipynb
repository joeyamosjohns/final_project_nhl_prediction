{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113604d0-a14e-489e-b9df-ae7029e39192",
   "metadata": {},
   "outputs": [],
   "source": [
    "##part 1\n",
    "##use models with default\n",
    "##use data set with H/A +1, -1\n",
    "##do full window for now\n",
    "\n",
    "##next:\n",
    "##check if just excluding first 10 days helps (chaotic)\n",
    "##check if different windows help\n",
    "\n",
    "##next\n",
    "## can try tuning (for loops by hand, or ... use grid_search (use ML mastery code))\n",
    "##-I think tuning will be faster ... just do by hand ... loop over the possible things \n",
    "##-ONE for loop over i = (a,b,c,d)... for each model i[0]\n",
    "\n",
    "##Orrr can try adding features ... here we have to worry about:\n",
    "##-adding basic features eg pp, and correct fo%\n",
    "##-scaling numericals\n",
    "##-dummy vars for categoricals (are there any?) besides H/A\n",
    "##-num_windows and which lengths for moving avgs\n",
    "##-filtering the features for increasing complexity inteligently\n",
    "##-There is a dicotemy: \n",
    "##(a)use H/A + numerics or  ... here I think it can be made more like time-series\n",
    "##(b) just use mumerics (moving avg) ... here I think the order of the games is not important (note Leung did this, and random train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425065e-8b4c-4144-8faf-662cffc9ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pischsada features #variation of Ottawa\n",
    "\n",
    "Goals for Total number of goals scored so far this season\n",
    "\n",
    "Goals against\n",
    "\n",
    "Total number of goals conceded so far thisseason\n",
    "\n",
    "Goals Differential Goals for – Goals against\n",
    "\n",
    "Power Play Success Rate Ratio – scoring a goal when 5 on 4\n",
    "\n",
    "Power Kill Success Rate Ratio – not conceding a goal when 4 on 5\n",
    "\n",
    "Shot % Goal scored/shots takenaaa\n",
    "\n",
    "Save % Goals conceded/shots saved\n",
    "\n",
    "Winning Streak Number of consecutive games won\n",
    "\n",
    "Conference Standing Latest ranking on conference table\n",
    "\n",
    "Fenwick Close % Possession ratio\n",
    "\n",
    "PDO Luck parameter\n",
    "\n",
    "5/5 Goal For/Against Ratio – 5 on 5 Goals For/Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ed52c4-918a-4668-baaa-5d2cfdd704e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Leung features (medium betting article)\n",
    "\n",
    "feat_Leung = ['ID', \n",
    "               'Date', \n",
    "               'HomeTeam', \n",
    "               'AwayTeam', \n",
    "               'CF%', \n",
    "               'CSh%',\n",
    "               'CSv%',\n",
    "               'FF%',\n",
    "               'FSh%',\n",
    "               'FSv%',\n",
    "               'GDiff',\n",
    "               'GF%',\n",
    "               'PDO',\n",
    "               'PENDiff',\n",
    "               'SF%',\n",
    "               'SDiff',\n",
    "               'Sh%',\n",
    "               'Sv',\n",
    "               'FOW%',\n",
    "               'W%',\n",
    "               'FavoritesW%',\n",
    "               'Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80e078-d78a-489a-82df-423d067a4711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db90e7-9a0e-47f4-8e2d-4fefa3d2dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak', 'pts%', 'win%', 'Fclose%', 'PDO'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300890f-58d1-4215-ae71-c81c5dab9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pischsada features #variation of Ottawa\n",
    "\n",
    "Goals for Total number of goals scored so far this season\n",
    "\n",
    "Goals against\n",
    "\n",
    "Total number of goals conceded so far thisseason\n",
    "\n",
    "Goals Differential Goals for – Goals against\n",
    "\n",
    "Power Play Success Rate Ratio – scoring a goal when 5 on 4\n",
    "\n",
    "Power Kill Success Rate Ratio – not conceding a goal when 4 on 5\n",
    "\n",
    "Shot % Goal scored/shots takenaaa\n",
    "\n",
    "Save % Goals conceded/shots saved\n",
    "\n",
    "Winning Streak Number of consecutive games won\n",
    "\n",
    "Conference Standing Latest ranking on conference table\n",
    "\n",
    "Fenwick Close % Possession ratio\n",
    "\n",
    "PDO Luck parameter\n",
    "\n",
    "5/5 Goal For/Against Ratio – 5 on 5 Goals For/Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f72ab2-5c0f-487b-89dd-7182cd68b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc56975-d90e-4dba-8e73-abc8fab0a04b",
   "metadata": {},
   "source": [
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef210bf-f076-4e91-abdb-68bb6d42f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "##couple evaluation functions ##removed model_name as variable\n",
    "def evaluate_binary_classification(y_test, y_pred, y_proba=None, graph = False):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    #try:\n",
    "    if y_proba != None:\n",
    "        rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        rocauc_score = \"no roc\"\n",
    "    #except: \n",
    "    #    pass     \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if graph == True:\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f'{model_name}', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1 score: \", f1)\n",
    "    print(\"rocauc: \", rocauc_score)\n",
    "    print(cm)\n",
    "    #return accuracy, precision, recall, f1, rocauc_score\n",
    "\n",
    "def evaluate_regression(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"mae\", mae)\n",
    "    print(\"mse\", mse)\n",
    "    print('r2', r2)\n",
    "    \n",
    "##display null values\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5ae41f-68fa-4db0-bbdb-88c6fb1b0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_bet_stats_mp.csv\")\n",
    "data.drop(columns=[ 'Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9235c761-bb3f-473c-a73d-86f9e157e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['won'] = data['won'].apply(int)\n",
    "data_playoffs = data.loc[data['playoffGame'] == 1, :].copy()  #set aside playoff games ... probably won't use them.\n",
    "data=  data.loc[data['playoffGame'] == 0, :].copy() \n",
    "\n",
    "#sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176e3bfd-ced9-49b0-ae6a-5cf09464f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(X, season):  #season 20162017 int; returns the list of all dates in chronological order from that season 20161004, 20161005, ...\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    dates_1 = list(set(X.loc[(X['date'] >= 900) & (X['date'] <= 1231) , :]['full_date']))  #2016 part\n",
    "    dates_2 = list(set(X.loc[(X['date'] >= 100) & (X['date'] <= 800) , :]['full_date']))  #2017 part\n",
    "    dates = dates_1 + dates_2 #all dates in order\n",
    "    return dates\n",
    "\n",
    "#sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c4bffe-9d3a-441b-9951-ff4022a37b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_HA_diff(X, season, list_var_names = None ):\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    X_H = X.loc[X['HoA'] == 'home',:].copy()\n",
    "    X_A = X.loc[X['HoA'] == 'away',:].copy()\n",
    "    X_H['goal_difference'] = X_H['goalsFor'] - X_H['goalsAgainst']  ##note every thing is based in home data\n",
    "    X_H.reset_index(drop = True, inplace = True)\n",
    "    X_A.reset_index(drop = True, inplace = True)\n",
    "    df_visitor = pd.get_dummies(X_H['nhl_name'], dtype=np.int64)\n",
    "    df_home = pd.get_dummies(X_A['nhl_name'], dtype=np.int64)\n",
    "    df_model = df_home.sub(df_visitor) \n",
    "    df_model['date'] = X_H['date']\n",
    "    df_model['full_date'] = X_H['full_date']\n",
    "    \n",
    "    df_model['game_id'] = X_H['game_id']\n",
    "    df_model['home_id'] = X_H['team_id']\n",
    "    df_model['away_id'] = X_A['team_id'] \n",
    "    y = X_H.loc[:,['date', 'full_date','game_id', 'Open','goal_difference', 'won']].copy()   ##these are from home team perspective; 'Open' is for betting \n",
    "    return (df_model, y)\n",
    "\n",
    "##try later maye \n",
    "def make_HA_concat(X, season, list_var_names = None ):\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    X_H = X.loc[X['HoA'] == 'home',:].copy()\n",
    "    X_A = X.loc[X['HoA'] == 'away',:].copy()\n",
    "    X_H['goal_difference'] = X_H['goalsFor'] - X_H['goalsAgainst']  ##note every thing is based in home data\n",
    "    X_H.reset_index(drop = True, inplace = True)\n",
    "    X_A.reset_index(drop = True, inplace = True)\n",
    "    df_visitor = pd.get_dummies(X_H['nhl_name'], dtype=np.int64)\n",
    "    df_home = pd.get_dummies(X_A['nhl_name'], dtype=np.int64)\n",
    "    \n",
    "    \n",
    "    df_model = df_home.sub(df_visitor) \n",
    "    \n",
    "    \n",
    "    df_model['date'] = X_H['date']\n",
    "    df_model['full_date'] = X_H['full_date']\n",
    "    \n",
    "    df_model['game_id'] = X_H['game_id']\n",
    "    df_model['home_id'] = X_H['team_id']\n",
    "    df_model['away_id'] = X_A['team_id'] \n",
    "    y = X_H.loc[:,['date', 'full_date','game_id', 'Open','goal_difference', 'won']].copy()   ##these are from home team perspective; 'Open' is for betting \n",
    "    return (df_model, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3598ea1f-e60b-46a8-a6da-a52e4c898438",
   "metadata": {},
   "outputs": [],
   "source": [
    "##have not written yet\n",
    "\n",
    "def top3_max_val_params(model, X, dates, drop_firs=False):\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333d4647-c363-417c-95e2-f68b49533cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for  regressors predicting wins - losses, can use this to turn output into win prediction \n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n",
    "\n",
    "#useage: v_make_win(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa3db4c-8b79-45a7-9c7c-5682319ac106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []   \n",
    "    \n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        \n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'goal_difference' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'goal_difference' ]\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results_dic['model_name'].append(model_name)\n",
    "        results_dic['date'].append(dates[i])\n",
    "    \n",
    "        results_dic['mae'].append(mae)\n",
    "        results_dic['mse'].append(mse)\n",
    "        results_dic['r2'].append(r2)\n",
    "        \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9989ff4-4152-488c-b97a-ca030013199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic ={}\n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['accuracy'] = []\n",
    "    results_dic['f1_score'] = []\n",
    "\n",
    "    #results_dic['precision'] = []\n",
    "  #  results_dic['recall'] = []\n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'won' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'won' ]\n",
    "    \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #recision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "        #recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred) #, average = None)\n",
    "            \n",
    "        results_dic['model_name'].append(model_name)  #append same model name every iter so same length as others\n",
    "        results_dic['date'].append(dates[i])\n",
    "                          \n",
    "        results_dic['accuracy'].append(accuracy)\n",
    "        results_dic['f1_score'].append(f1)\n",
    "        #results_dic['precision'].append(precision)\n",
    "        #results_dic['recall'].append(recall)\n",
    "    results_dic['model_name'].append('model_name'+'_avg')  #append same model name every iter so same length as others\n",
    "    results_dic['date'].append('average')\n",
    "    results_dic['accuracy'].append(round(np.mean(np.array(results_dic['accuracy'])), 2) ) \n",
    "    results_dic['f1_score'].append(round(np.mean(np.array(results_dic['f1_score'])), 2) ) \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd847ff-1993-4bb6-ad29-4ace1738d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons = sorted(set(data['season']))\n",
    "#all_seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880c7b4-2f63-404c-a1fb-b4f4320ba204",
   "metadata": {},
   "source": [
    "1. two versions of dummies for teams - teams plus H/A and teamH - teamA \n",
    "2. play with add/remove when in season (hypothesis: offense early defense favored late) ---> 5 vars for where in year ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54b8d2f-7d1b-4ce1-9028-83be78d7487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dajfda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"dajfdajjj\"[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f59793-6360-4ffa-b954-a11a72b12733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "         ... \n",
       "29933    50.9\n",
       "29934    53.3\n",
       "29935    46.7\n",
       "29936    48.2\n",
       "29937    51.8\n",
       "Name: faceOffWinPercentage, Length: 28358, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['faceOffWinPercentage'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16dc325e-ea92-481b-a48a-a63407b601c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(statFor, statAway):\n",
    "    return statFor - statAway\n",
    "\n",
    "v_make_diff = np.vectorize(make_diff)\n",
    "\n",
    "def make_per(statFor, statAway):  #example FOWFor/(FOWFor + FOWAgainst)  or ShAt\n",
    "    return statFor/(statFor+statAway)\n",
    "\n",
    "v_make_per = np.vectorize(make_per)\n",
    "\n",
    "##have to adjust later depending what is convenient to use for stat name ... \n",
    "\n",
    "#not using k_days_back .. will use a unioversal fn to just avg past games...\n",
    "#makes more sense ,,, if they get a 1000 shots against one game, don't want that to leak into \n",
    "#other games .. \n",
    "def get_per(X, stat_name, k_days_back = 1000  ): #do max(current -k, 0) so this will be all games\n",
    "    #stat_name = goalsFor or faceoffsWonFor  example to keep in mind ... mp style\n",
    "    ##we do this so we can loop thru existing names in our feature list\n",
    "    stat_name = stat_name[:-3]  #remove last 3\n",
    "    statFor = stat_name+'For'\n",
    "    statAgainst = stat_name+'Against'\n",
    "    return v_make_per(X[statFor],X[statAgainst])\n",
    "\n",
    "\n",
    "def get_diff(X, stat_name, k_days_back = 1000  ): #do max(current -k, 0) so this will be all games\n",
    "    #stat_name = goalsFor or faceoffsWonFor  example to keep in mind ... mp style\n",
    "    ##we do this so we can loop thru existing names in our feature list\n",
    "    stat_name = stat_name[:-3]  #remove last 3\n",
    "    statFor = stat_name+'For'\n",
    "    statAgainst = stat_name+'Against'\n",
    "    return v_make_diff(X[statFor],X[statAgainst])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4756395-f74e-4ae2-be80-1aa72b5c05e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 7, 8]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,3,4, 7, 8][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f33b5c68-facf-4f0a-ae95-0fbe9760bf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "X_16 = data.loc[data['season'] == 20162017, :].copy()\n",
    "all_dates = sorted(list(X_16['full_date']))\n",
    "\n",
    "date1 = 20161022\n",
    "dates_bef_date1 = [date for date in all_dates if date < date1]\n",
    "dates_bef_date1 = dates_bef_date1[-k :]\n",
    "\n",
    "stat_name = 'goalsFor'\n",
    "sk = str(k)\n",
    "X_16[stat_name+sk+'_avg'] = np.NaN \n",
    "\n",
    "X_bef_date1 = X_16.loc[X_16['full_date'].isin(dates_bef_date1), :]\n",
    "teams_date1 = sorted(list(X_bef_date1['nhl_name']))\n",
    "nhl_name = 'ANA' \n",
    "X = X_16.copy()\n",
    "k_avg = np.mean(X_bef_date1.loc[(X_bef_date1['nhl_name'] == nhl_name) , stat_name])\n",
    "X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name+sk+'_avg'] =k_avg\n",
    "k_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "76fa5463-36e5-46f4-b8cb-ebaa5cec7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = sorted(set((X_16['full_date'])))\n",
    "\n",
    "X_16.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fbb57027-0de5-49df-9d4f-39429a7237c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #num of games back max(xurrent - k, 0) = 0 for 1000\n",
    "     #here X_N = data.iloc[0:date-1, :] all games from all days before present day.  \n",
    "    #here X = whole season or whatever chumk you want\n",
    "def get_k_game_avg(data, stat_name, k_days_back= 3000 ): #k_days_back\n",
    "    X = data.copy()\n",
    "    k = str(k_days_back)\n",
    "    all_dates = sorted(set(X['full_date']))\n",
    "    X[stat_name+k+'_avg'] = np.NaN  #set up column\n",
    "    \n",
    "    #take care of first day of season ... might want to leave it NaN ... nahhh\n",
    "    date0 = all_dates[0]\n",
    "    X.loc[(X['full_date'] == date0), stat_name+k+'_avg'] =  X.loc[(X['full_date'] == date0), stat_name]\n",
    "    \n",
    "    for date1 in all_dates[1:]: #all but first date so don't get emopty\n",
    "        dates_bef_date1 = [date for date in all_dates if date < date1]\n",
    "        dates_bef_date1 = dates_bef_date1[-k_days_back :] # this grabs all or the last k days of list\n",
    "        \n",
    "        X_bef_date1 = X.loc[X['full_date'].isin(dates_bef_date1), :]\n",
    "        teams_date1 = sorted(set(X_bef_date1['nhl_name']))\n",
    "        \n",
    "        #first take care of all teams not present in the previous days (only a few)\n",
    "        for nhl_name in set(X['nhl_name']).difference(set(X_bef_date1['nhl_name'])):\n",
    "            k_avg = X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name] ##should be single number anyway\n",
    "            X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name+k+'_avg'] =k_avg\n",
    "        \n",
    "        \n",
    "        #this is the main step\n",
    "        for nhl_name in teams_date1:\n",
    "            k_avg = np.mean(X_bef_date1.loc[(X_bef_date1['nhl_name'] == nhl_name) , stat_name])\n",
    "            X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name+k+'_avg'] =k_avg\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "85b220fa-ee22-4468-918a-80e054f54b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "##I do not the Emperor's prize damaged. We will test it on Captain Solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "33a26dfe-764c-4d03-873c-85da97b2eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_k_game_avg(X_16, 'goalsFor', 10)\n",
    "\n",
    "\n",
    "#data['faceOffWinPercentage'] = get_per(data, 'faceOffsWonFor')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "084fb45d-0e81-49e7-90ed-341ec6f1b6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Type</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>goalsFor20_avg</th>\n",
       "      <td>8</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_date</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_id</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goalsFor</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goalsFor10_avg</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total     Type   Percent\n",
       "goalsFor20_avg      8  float64  0.003252\n",
       "full_date           0    int64  0.000000\n",
       "team_id             0    int64  0.000000\n",
       "goalsFor            0  float64  0.000000\n",
       "goalsFor10_avg      0  float64  0.000000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "perc_null(X_16.loc[:, ['full_date', 'team_id', 'goalsFor', 'goalsFor10_avg', 'goalsFor20_avg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3ab206bc-05ac-481c-b525-7a68b6b4dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_16.loc[:, ['full_date', 'nhl_name', 'goalsFor', 'goalsFor10_avg', 'goalsFor20_avg']].iloc[0:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ac04351-8fa4-4823-8aef-7322612fce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.483871\n",
       "1        0.516129\n",
       "2        0.466667\n",
       "3        0.533333\n",
       "4        0.630435\n",
       "           ...   \n",
       "29933    0.508772\n",
       "29934    0.533333\n",
       "29935    0.466667\n",
       "29936    0.222222\n",
       "29937    0.777778\n",
       "Name: faceOffWinPercentage, Length: 28358, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['faceOffWinPercentage']  #this is for each game only. I think it is ok to just avg these ... ffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ebeaad19-6757-4097-9b8d-619af43e2cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_16['penaltiesAgainst'] == X_16['powerPlayOpportunities']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c024819-0bfa-4147-a2b6-f535f197caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "edee9f22-431e-4c16-8daa-3c79131cffec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AwayTeam',\n",
       " 'CF%',\n",
       " 'CSh%',\n",
       " 'CSv%',\n",
       " 'Date',\n",
       " 'FF%',\n",
       " 'FOW%',\n",
       " 'FSh%',\n",
       " 'FSv%',\n",
       " 'FavoritesW%',\n",
       " 'GDiff',\n",
       " 'GF%',\n",
       " 'HomeTeam',\n",
       " 'ID',\n",
       " 'PDO',\n",
       " 'PENDiff',\n",
       " 'Result',\n",
       " 'SDiff',\n",
       " 'SF%',\n",
       " 'Sh%',\n",
       " 'Sv',\n",
       " 'W%'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I add 'pts%', 'win%', 'xgoal%', ('Fsh%' ...), grouped_4 date? \n",
    "\n",
    "##Leung features (medium betting article) same as Morrison pretty much and other guy not much diff ... \n",
    "\n",
    "set(['ID', \n",
    "          'Date', \n",
    "               'HomeTeam', \n",
    "               'AwayTeam', \n",
    "               'CF%', \n",
    "               'CSh%',\n",
    "               'CSv%',\n",
    "               'FF%',\n",
    "               'FSh%',\n",
    "               'FSv%',\n",
    "               'GDiff',\n",
    "               'GF%',\n",
    "               'PDO',\n",
    "               'PENDiff',\n",
    "               'SF%',\n",
    "               'SDiff',\n",
    "               'Sh%',\n",
    "               'Sv',\n",
    "               'FOW%',\n",
    "               'W%',\n",
    "               'FavoritesW%',\n",
    "               'Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250dc155-3cd5-42bb-abd6-886a02605b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Pis_plus = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak', 'pts%', 'win%', 'Fclose%', 'PDO'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "58cd5cbe-4bcf-4fe1-a8f5-8f5b8b72f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features I need to do this ...\n",
    "feat_for_Pis = ['full_date','season', 'game_id', \n",
    "\n",
    "'nhl_name','HoA',\n",
    " 'opposingTeam', \n",
    "\n",
    "  'goalsAgainst',\n",
    " 'goalsFor',\n",
    "'powerPlayGoals',\n",
    " 'powerPlayOpportunities',     \n",
    " \n",
    "'shotsOnGoalAgainst',\n",
    "  'shotsOnGoalFor',\n",
    "'savedShotsOnGoalAgainst',\n",
    " 'savedShotsOnGoalFor',  \n",
    "\n",
    "'fenwickPercentage',\n",
    "  \n",
    "#'win_streak_grouped_10', 'conference_standing_grouped_10',\n",
    "#'PDO'  \n",
    "\n",
    "#targets \n",
    "  'won',\n",
    " 'settled_in',] #could later try to train classifier to predict this ... tough tho --> reg or no\n",
    "    \n",
    "\n",
    "extra = ['corsiPercentage', \n",
    "    'penaltiesAgainst',\n",
    " 'penaltiesFor', \n",
    "    'shotAttemptsAgainst',\n",
    " 'shotAttemptsFor',\n",
    "    'unblockedShotAttemptsAgainst',\n",
    " 'unblockedShotAttemptsFor', 'savedUnblockedShotAttemptsAgainst',\n",
    " 'savedUnblockedShotAttemptsFor',\n",
    " 'xGoalsPercentage','scoreVenueAdjustedxGoalsAgainst',\n",
    " 'scoreVenueAdjustedxGoalsFor','blockedShotAttemptsAgainst',\n",
    " 'blockedShotAttemptsFor',\n",
    "\n",
    " 'flurryAdjustedxGoalsAgainst',\n",
    " 'flurryAdjustedxGoalsFor',\n",
    " 'flurryScoreVenueAdjustedxGoalsAgainst',\n",
    " 'flurryScoreVenueAdjustedxGoalsFor',\n",
    " 'missedShotsAgainst',\n",
    " 'missedShotsFor',]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e39bd4-ec25-43e2-aa40-80aaf07b7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
