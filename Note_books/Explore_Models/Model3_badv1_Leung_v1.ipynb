{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b93318-b204-4321-a902-e019ed05e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09481dd-9747-4663-8591-f470375f62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee37b61a-b150-4bf7-b16b-ca7685251210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd1f830-faa1-449b-99ec-a9dac336049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d23f97-3b91-4868-b566-bed9d7dd76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd905eb-ae20-4c09-a097-d9ced6c6931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a54a87-fb7f-4642-a65e-b2a6c2a6b530",
   "metadata": {},
   "source": [
    "##TUNING INFO \n",
    "\n",
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bab795dd-c9bf-4524-abdc-c3b9ba2e5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_LJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d991107-60b5-4e81-a9ba-12814dfe9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X['season'] = X['season'].apply(int)\n",
    "X['game_id'] = X['game_id'].apply(int)\n",
    "X['mp_date'] = X['mp_date'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "803c4a79-77ee-4168-abfe-ac2fe7ba1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20172018    1218\n",
       "20142015    1180\n",
       "20152016    1180\n",
       "20112012    1177\n",
       "20162017    1172\n",
       "20132014    1166\n",
       "20092010    1108\n",
       "20082009    1093\n",
       "20102011    1091\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d21102ad-152a-4535-a93b-d2a7f72e15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['Unnamed: 0', 'game_id', 'mp_date', 'season', 'home_team', 'away_team',\n",
    "       'home_odds', 'away_odds', 'home_goals', 'away_goals', 'home_win',\n",
    "       'settled_in', ]\n",
    "\n",
    "x_cols = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']\n",
    "columns_to_scale = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']  ##same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4c9ae08-71a1-45e1-aeb8-4d710ee856a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = np.array(X.loc[(X['season'] != 20172018), x_cols].copy())\n",
    "  #features test-train\n",
    "Y = X.loc[(X['season'] != 20172018), y_cols].copy()\n",
    "   #targets\n",
    "y = np.array(Y['home_win']).reshape(-1,1)\n",
    "\n",
    "\n",
    "              \n",
    "x_17 = X.loc[(X['season'] == 20172018), x_cols].copy()  #features test-train\n",
    "Y_17 = X.loc[(X['season'] == 20172018), y_cols].copy()   #targets\n",
    "y_17 = np.array(Y_17['home_win']).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91aeedd8-01a5-490e-91d9-e59785f0a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10385, 26) (9167, 14) (9167, 1) (1218, 14) (9167, 1) (9167, 1, 9167, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, x.shape, y.shape, x_17.shape, y_17.shape,  y.shape + y_17.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5b76217-38e0-4995-bce3-b98392370128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9167, 14)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] != 20172018), x_cols].copy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb85e93d-4ae3-47cc-b92c-81125796e884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9167, 14)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52c84ef4-9317-4890-b466-339aa3657ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9167, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ce6940c-1df9-4d1a-aeac-087fa6da4940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20142015    1180\n",
       "20152016    1180\n",
       "20112012    1177\n",
       "20162017    1172\n",
       "20132014    1166\n",
       "20092010    1108\n",
       "20082009    1093\n",
       "20102011    1091\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75550a45-7737-4ea8-9184-1f433157700d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20172018    1218\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_17['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9ecd118-f9dc-456b-8b1d-95f1e50d1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f0df089-4313-488a-994f-1a628ad0117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.74      , -0.19374416,  0.48597919, ..., -1.52      ,\n",
       "        -0.41265553,  0.3       ],\n",
       "       [ 4.45      ,  1.03837499,  1.48999723, ...,  3.32      ,\n",
       "         2.26641656,  2.9       ],\n",
       "       [-0.03      ,  1.86657399, -0.32646438, ...,  0.13      ,\n",
       "         4.13556804, -1.16      ],\n",
       "       ...,\n",
       "       [ 2.22      ,  0.46139509, -0.1267105 , ...,  4.63      ,\n",
       "         0.56255271, -0.57      ],\n",
       "       [ 3.31      , -1.68862357, -1.05321944, ...,  1.12      ,\n",
       "        -3.19214922, -0.96      ],\n",
       "       [-0.6       ,  0.41824677, -0.10439703, ..., -1.38      ,\n",
       "         1.07523143, -0.24      ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e6d1c92-3ca5-447e-a9da-9393db3b9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "x_train_sc = std_scal.fit_transform(x_train)\n",
    "    \n",
    "#fit the scaler from train portion to the test portion \n",
    "x_test_sc = std_scal.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "38b8f56c-f0f0-4672-ac9c-50cdeed0696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1cb1102e-306b-478c-8356-bc3e55a8f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-8548c9af614d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de6992da-3597-4ffc-9d72-5f89df4ddfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##handy code from Leung\n",
    "\n",
    "# Taken from Siraj Raval\n",
    "#for measuring training time#for me \n",
    "from time import time \n",
    "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
    "#It considers both the precision p and the recall r of the test to compute \n",
    "#the score: p is the number of correct positive results divided by the number of \n",
    "#all positive results, and r is the number of correct positive results divided by \n",
    "#the number of positive results that should have been returned. The F1 score can be \n",
    "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
    "#reaches its best value at 1 and worst at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for test set: \", f1, acc )\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score for test set: \",  f1, acc)\n",
    "\n",
    "def train_predictproba(clf, X_train, y_train, X_test, y_test):\n",
    "    #Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for training set: \", f1, acc) \n",
    "    \n",
    "    display(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "65857f1c-005a-411c-b8d2-2f1430170d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 7333. . .\n",
      "Trained model in 0.0551 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "0.6724046328764213 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "F1 score and accuracy score for test set:  0.6724046328764213 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "Made predictions in 0.0002 seconds.\n",
      "F1 score and accuracy score for test set:  0.6586310804993544 [0.54798255 0.54798255 0.54798255 ... 0.54798255 0.54798255 0.54798255]\n",
      "\n",
      "Training a SVC using a training set size of 7333. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 3.1824 seconds\n",
      "Made predictions in 4.6313 seconds.\n",
      "0.6898294377763741 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "F1 score and accuracy score for test set:  0.6898294377763741 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "Made predictions in 1.1525 seconds.\n",
      "F1 score and accuracy score for test set:  0.6632868610054923 [0.45201745 0.54798255 0.54798255 ... 0.54798255 0.54798255 0.54798255]\n",
      "\n",
      "Training a XGBClassifier using a training set size of 7333. . .\n",
      "[15:41:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.5148 seconds\n",
      "Made predictions in 0.0057 seconds.\n",
      "0.9511898980087421 [0.45179326 0.45179326 0.45179326 ... 0.54820674 0.54820674 0.54820674]\n",
      "F1 score and accuracy score for test set:  0.9511898980087421 [0.45179326 0.45179326 0.45179326 ... 0.54820674 0.54820674 0.54820674]\n",
      "Made predictions in 0.0019 seconds.\n",
      "F1 score and accuracy score for test set:  0.5778414517669532 [0.45201745 0.54798255 0.54798255 ... 0.45201745 0.54798255 0.45201745]\n",
      "\n",
      "Training a SVC using a training set size of 7333. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 17.1866 seconds\n",
      "Made predictions in 4.6534 seconds.\n",
      "0.6898294377763741 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "F1 score and accuracy score for test set:  0.6898294377763741 [0.54820674 0.54820674 0.54820674 ... 0.54820674 0.54820674 0.45179326]\n",
      "Made predictions in 1.1633 seconds.\n",
      "F1 score and accuracy score for test set:  0.6632868610054923 [0.45201745 0.54798255 0.54798255 ... 0.54798255 0.54798255 0.54798255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgbq\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = SVC(random_state = 43, kernel = 'rbf')\n",
    "clf_C = xgb.XGBClassifier(seed = 44)\n",
    "clf_D = SVC(probability=True)\n",
    "\n",
    "train_predict(clf_A, x_train_sc, y_train, x_test_sc, y_test)\n",
    "print('')\n",
    "train_predict(clf_B, x_train_sc, y_train, x_test_sc, y_test)\n",
    "print('')\n",
    "train_predict(clf_C, x_train_sc, y_train, x_test_sc, y_test)\n",
    "print('')\n",
    "train_predict(clf_D, x_train_sc, y_train, x_test_sc, y_test)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff0a7d-7a7b-41e3-8820-bb719d97abc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
