{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b210964-63eb-4766-bac4-d91ee0dfbfe1",
   "metadata": {},
   "source": [
    "##I am splitting v3_Clean_model_add_Pis_feat.ipynb into 2 notebooks \n",
    "\n",
    "-this one on modelling and \n",
    "\n",
    "-another one on creating stats data set (just Pisch for now)\n",
    "v1_stats_tools_Pish.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252a81d7-900b-46e1-9c38-4f1c9cdb3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "##part 1\n",
    "##use models with default\n",
    "##use data set with H/A +1, -1\n",
    "##do full window for now\n",
    "\n",
    "##next:\n",
    "##check if just excluding first 10 days helps (chaotic)\n",
    "##check if different windows help\n",
    "\n",
    "##next\n",
    "## can try tuning (for loops by hand, or ... use grid_search (use ML mastery code))\n",
    "##-I think tuning will be faster ... just do by hand ... loop over the possible things \n",
    "##-ONE for loop over i = (a,b,c,d)... for each model i[0]\n",
    "\n",
    "##Orrr can try adding features ... here we have to worry about:\n",
    "##-adding basic features eg pp, and correct fo%\n",
    "##-scaling numericals\n",
    "##-dummy vars for categoricals (are there any?) besides H/A\n",
    "##-num_windows and which lengths for moving avgs\n",
    "##-filtering the features for increasing complexity inteligently\n",
    "##-There is a dicotemy: \n",
    "##(a)use H/A + numerics or  ... here I think it can be made more like time-series\n",
    "##(b) just use mumerics (moving avg) ... here I think the order of the games is not important (note Leung did this, and random train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778fca46-90be-4c9f-a057-1e41ffea0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "##couple evaluation functions ##removed model_name as variable\n",
    "def evaluate_binary_classification(y_test, y_pred, y_proba=None, graph = False):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    #try:\n",
    "    if y_proba != None:\n",
    "        rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        rocauc_score = \"no roc\"\n",
    "    #except: \n",
    "    #    pass     \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if graph == True:\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f'{model_name}', y=1.1)\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1 score: \", f1)\n",
    "    print(\"rocauc: \", rocauc_score)\n",
    "    print(cm)\n",
    "    #return accuracy, precision, recall, f1, rocauc_score\n",
    "\n",
    "def evaluate_regression(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"mae\", mae)\n",
    "    print(\"mse\", mse)\n",
    "    print('r2', r2)\n",
    "    \n",
    "##display null values\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18af7514-a756-444a-bd2f-4de970ba321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []   \n",
    "    \n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        \n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'goal_difference' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'goal_difference' ]\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results_dic['model_name'].append(model_name)\n",
    "        results_dic['date'].append(dates[i])\n",
    "    \n",
    "        results_dic['mae'].append(mae)\n",
    "        results_dic['mse'].append(mse)\n",
    "        results_dic['r2'].append(r2)\n",
    "        \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7ec9a6-f01d-47c0-b2d1-02902750ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic ={}\n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['accuracy'] = []\n",
    "    results_dic['f1_score'] = []\n",
    "\n",
    "    #results_dic['precision'] = []\n",
    "  #  results_dic['recall'] = []\n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'won' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'won' ]\n",
    "    \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #recision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "        #recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred) #, average = None)\n",
    "            \n",
    "        results_dic['model_name'].append(model_name)  #append same model name every iter so same length as others\n",
    "        results_dic['date'].append(dates[i])\n",
    "                          \n",
    "        results_dic['accuracy'].append(accuracy)\n",
    "        results_dic['f1_score'].append(f1)\n",
    "        #results_dic['precision'].append(precision)\n",
    "        #results_dic['recall'].append(recall)\n",
    "    results_dic['model_name'].append('model_name'+'_avg')  #append same model name every iter so same length as others\n",
    "    results_dic['date'].append('average')\n",
    "    results_dic['accuracy'].append(round(np.mean(np.array(results_dic['accuracy'])), 2) ) \n",
    "    results_dic['f1_score'].append(round(np.mean(np.array(results_dic['f1_score'])), 2) ) \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c935eaa1-b629-406d-94f1-147c6daed626",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbaf7e-46af-4a63-9a9c-bbe35291577d",
   "metadata": {},
   "source": [
    "##TUNING INFO \n",
    "\n",
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcbb7207-4cc5-47b0-aa6b-7ba80d933695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC(kernel = 'rbf')\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=5, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36d368b-45fc-44c1-a5ff-579fea4fe286",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe6f08-f93a-4e4d-a225-f4e4cf4160d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_Pis.loc[13:, 'won'].copy()\n",
    "X = data_dummies_Pis.copy()\n",
    "X.shape\n",
    "X[300:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe1314-e15e-415a-bb5a-d0bde3acf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "    model.fit(X.iloc[:300 :], y[:300])\n",
    "    y_pred = model.predict(X.iloc[300:, :])\n",
    "    y_test = y[300:].copy()\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(model, acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bd45e-bd4c-4f88-9632-a87cd5e6454e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e32044-aa37-4fa3-80df-59d8a38b18a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac75cadf-54b7-4931-8ad9-92ccfedd2891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b6b57-8f71-4677-90bd-ea0fc86ec091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
