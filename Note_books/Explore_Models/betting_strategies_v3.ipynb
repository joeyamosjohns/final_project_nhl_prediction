{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34da09a1-4fa6-41ec-8b5e-4feb04bb7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c75c22e-848f-4a4f-8d6c-d32797909c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5e3250-ba9b-4518-8a81-f30975061070",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()\n",
    "\n",
    "\n",
    "##no tuning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cd78a3-04d6-435a-8952-356dac59f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['Unnamed: 0', 'game_id', 'mp_date', 'season', 'home_team', 'away_team',\n",
    "       'home_odds', 'away_odds', 'home_goals', 'away_goals', 'goal_diff_target', 'home_win',\n",
    "       'settled_in', ]\n",
    "\n",
    "x_cols = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']\n",
    "columns_to_scale = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']  ##same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "0698730d-36ec-4473-a417-b9edf18de38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10385, 27)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_LJ.csv')\n",
    "\n",
    "X['season'] = X['season'].apply(int)\n",
    "X['game_id'] = X['game_id'].apply(int)\n",
    "X['mp_date'] = X['mp_date'].apply(int)\n",
    "X['goal_diff_target'] = X['home_goals'] - X['away_goals']\n",
    "X.loc[X['home_odds'] == X['away_odds'],  ['away_odds']]=110  #(!)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96607d-1f35-49f7-b1fd-ece6605a0009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "e5209e36-4816-41db-9eb1-cd6ee6827381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_early(X):\n",
    "    filt_no_early  = (X['mp_date'].apply(lambda x : x% 10**4) < 900) | (1100 < X['mp_date'].apply(lambda x : x% 10**4))\n",
    "    return X.loc[filt_no_early, : ].copy()  ## keep games < 900 and > 1100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "6cb36b14-8385-4907-a30b-8ef403fcc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##split data \n",
    "\n",
    "x = np.array(X.loc[(X['season'] <= 20152016), x_cols].copy())\n",
    "  #features test-train\n",
    "Y = X.loc[(X['season'] <= 20152016), y_cols].copy()\n",
    "   #targets\n",
    "y = np.array(Y['home_win']).reshape(-1,1)\n",
    "\n",
    "\n",
    "              \n",
    "x_16 = X.loc[(X['season'] == 20162017), x_cols].copy()  #features test-train\n",
    "Y_16 = X.loc[(X['season'] == 20162017), y_cols].copy()   #targets\n",
    "y_16 = np.array(Y_16['home_win']).reshape(-1,1)\n",
    "\n",
    "x_17 = X.loc[(X['season'] > 20162017), x_cols].copy()  #features test-train\n",
    "Y_17 = X.loc[(X['season'] > 20162017), y_cols].copy()   #targets\n",
    "y_17 = np.array(Y_17['home_win']).reshape(-1,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d81f6d-b7f2-41c6-935a-0903fb0994dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162017    1060\n",
       "20172018    1052\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] >= 20162017), :]['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1186beb4-91d6-47b9-8120-28a064d658f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20142015    1046\n",
       "20112012    1037\n",
       "20152016    1036\n",
       "20132014     994\n",
       "20082009     971\n",
       "20102011     962\n",
       "20092010     946\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] <= 20152016), :]['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95579dd2-f1f4-484a-8932-5e0c58f53b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] <= 20152016), :]['season'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c08e0c-1a34-4216-b760-98e3602f6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9104, 27)\n",
      "(6992, 14) (6992, 13) (6992, 1)\n",
      "(1060, 14) (1060, 1)\n",
      "(1052, 14) (1052, 1)\n",
      "sum  6992 1060 1052  is:  9104\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(x.shape, Y.shape, y.shape)\n",
    "print(x_16.shape, y_16.shape)\n",
    "print(x_17.shape, y_17.shape)\n",
    "print('sum ', y.shape[0], y_16.shape[0], y_17.shape[0], ' is: ', y.shape[0] + y_16.shape[0]+y_17.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa8c0e8c-6fd4-4fa7-adb2-09de0a57be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20142015    1046\n",
       "20112012    1037\n",
       "20152016    1036\n",
       "20132014     994\n",
       "20082009     971\n",
       "20102011     962\n",
       "20092010     946\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d646e4-ca06-4cf3-ae8b-0fec4683866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162017    1060\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_16['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93df204b-03a2-4e1d-bf85-452971611b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20172018    1052\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_17['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "eecf9232-215c-4c28-af05-e8f3afa5abef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-502-0df0e7b0d549>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-502-0df0e7b0d549>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    def fit_model(model, print_results = True, tuned = False)\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()\n",
    "\n",
    "\n",
    "##no tuning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "x_train_sc = std_scal.fit_transform(x_train)\n",
    "    \n",
    "#fit the scaler from train portion to the test portion \n",
    "x_test_sc = std_scal.transform(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0, max_iter = 1000)\n",
    "svc = SVC(probability = True)\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "##quick checks \n",
    "#for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "def fit_model(model, print_results = True, tuned = False)    \n",
    "    model.fit(x_train_sc, y_train.ravel())\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test_sc)\n",
    "    y_predt= model.predict(x_train_sc)  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    acct = accuracy_score(y_train, y_predt)\n",
    "    f1t = f1_score(y_train,y_predt)\n",
    "    if tuned:\n",
    "        tuned= 'WITH tuning'\n",
    "    else\n",
    "        tuned = 'NO tuning'\n",
    "    \n",
    "    if print_results:  \n",
    "        print(str(model)[0:12], tuned+ 'TEST acc, f1: ', acc, f1, 'training acct, f1t: ', acct, f1t)\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5151e5-5b05-4af4-8ba4-9eb3e9d22edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.07000000e+00,  3.88836773e+00, -1.50203584e+00, ...,\n",
       "         0.00000000e+00,  6.54126895e+00, -2.47000000e+00],\n",
       "       [-5.33000000e+00,  3.22158462e-01,  7.96868447e-01, ...,\n",
       "        -8.69000000e+00,  7.75485350e-01,  2.28000000e+00],\n",
       "       [-1.13900000e+01,  1.29385506e+00, -7.31934901e-01, ...,\n",
       "        -1.05100000e+01,  2.16503340e+00, -2.47000000e+00],\n",
       "       ...,\n",
       "       [-1.07000000e+00, -1.70848125e-03, -6.54668512e-02, ...,\n",
       "        -2.04000000e+00, -3.28207435e-01,  5.00000000e-01],\n",
       "       [ 4.45000000e+00, -3.02955417e-01,  7.35640597e-01, ...,\n",
       "         4.42000000e+00, -2.41020059e-01,  1.24000000e+00],\n",
       "       [ 3.87000000e+00,  2.48248880e-01,  4.01685000e-01, ...,\n",
       "         6.00000000e+00,  3.36489035e-01,  3.90000000e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c760d5f2-245b-4abf-bc98-8e1510805cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() 20162017, no tuning, TEST:  0.5773584905660377 0.6985195154777928\n",
      "RidgeClassif 20162017, no tuning, TEST:  0.5311320754716982 0.6452533904354033\n",
      "RandomForest 20162017, no tuning, TEST:  0.5783018867924529 0.7091737150292778\n",
      "GaussianNB() 20162017, no tuning, TEST:  0.5735849056603773 0.627677100494234\n",
      "LogisticRegr 20162017, no tuning, TEST:  0.5528301886792453 0.6814516129032259\n",
      "BaggingClass 20162017, no tuning, TEST:  0.5132075471698113 0.5401069518716578\n",
      "GradientBoos 20162017, no tuning, TEST:  0.5707547169811321 0.6838082001389855\n",
      "XGBClassifie 20162017, no tuning, TEST:  0.5311320754716982 0.6120218579234973\n"
     ]
    }
   ],
   "source": [
    "#check on 2016\n",
    "\n",
    "x_test2 = std_scal.transform(x_16).copy()\n",
    "y_test2 = y_16.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], '20162017, no tuning, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8dc7e0de-5c4d-45c7-84fc-b9f7c774c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() 20172018, no tuning, TEST:  0.5884030418250951 0.6931254429482636\n",
      "RidgeClassif 20172018, no tuning, TEST:  0.5884030418250951 0.6913756236635781\n",
      "RandomForest 20172018, no tuning, TEST:  0.6036121673003803 0.7098121085594988\n",
      "GaussianNB() 20172018, no tuning, TEST:  0.5731939163498099 0.6286186931348222\n",
      "LogisticRegr 20172018, no tuning, TEST:  0.5874524714828897 0.6917613636363635\n",
      "BaggingClass 20172018, no tuning, TEST:  0.529467680608365 0.5638766519823788\n",
      "GradientBoos 20172018, no tuning, TEST:  0.5998098859315589 0.6906686260102866\n",
      "XGBClassifie 20172018, no tuning, TEST:  0.55893536121673 0.6340694006309148\n"
     ]
    }
   ],
   "source": [
    "#check on 2017\n",
    "\n",
    "x_test2 = std_scal.transform(x_17).copy()\n",
    "y_test2 = y_17.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], '20172018, no tuning, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11072809-01e1-4905-94d3-0e356355c0a0",
   "metadata": {},
   "source": [
    "#can do version where we get y regr version at beinning ... do all teh regression stuff ... \n",
    "then for later cells do y = v_win(y) for classifiers ... \n",
    "\n",
    "##regression models now ...\n",
    "\n",
    "y = Y['goal_diff_target'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "x_train_sc = std_scal.fit_transform(x_train)\n",
    "    \n",
    "#fit the scaler from train portion to the test portion \n",
    "x_test_sc = std_scal.transform(x_test)\n",
    "\n",
    "\n",
    "lr = Ridge(alpha=50000) \n",
    "rfr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [lr, rfr, xgbr]:\n",
    "    model.fit(x_train_sc, y_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test_sc)\n",
    "    print(y_pred[0:5])\n",
    "    y_predw = v_win(y_pred)\n",
    "    y_predt= model.predict(x_train_sc)  \n",
    "    y_predwt = v_win(y_predt) \n",
    "    y_trainw = v_win(y_train)\n",
    "    y_testw = v_win(y_test)  #same as usual win/loss\n",
    "    acc = accuracy_score(y_testw, y_predw)\n",
    "    f1 = f1_score(y_testw,y_predw)\n",
    "    acct = accuracy_score(y_trainw, y_predwt)\n",
    "    f1t = f1_score(y_trainw,y_predwt)\n",
    "    \n",
    "  \n",
    "    print(str(model)[0:20], 'TEST: ', acc, f1 ,'training : ', acct, f1t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "31a5eba7-807e-4e15-8aad-2833565bca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, pr with tuning TEST:  0.5668334524660472 0.6666666666666667 training :  0.6264974074736277 0.7127732710023373\n",
      "RidgeClassif with tuning TEST:  0.5675482487491065 0.6606842400448683 training :  0.5758984444841766 0.6692693809258226\n",
      "RandomForest with tuning TEST:  0.5668334524660472 0.6521239954075775 training :  0.8119077418201323 0.8471818710052295\n",
      "GaussianNB() with tuning TEST:  0.5689778413152251 0.6045901639344262 training :  0.5649919542284999 0.606119475473531\n",
      "LogisticRegr with tuning TEST:  0.5639742673338098 0.6545866364665911 training :  0.5730377257285894 0.6658270361041141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClass with tuning TEST:  0.5503931379556827 0.6162294081757168 training :  1.0 1.0\n",
      "GradientBoos with tuning TEST:  0.5725518227305219 0.6621468926553672 training :  0.6676202395851958 0.7381321312860967\n",
      "[15:41:06] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifie with tuning TEST:  0.5539671193709793 0.6450511945392492 training :  0.7201859467191132 0.7769066286528866\n"
     ]
    }
   ],
   "source": [
    "## some tries at tuning here \n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12, stratify=y)\n",
    "\n",
    "#do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "x_train_sc = std_scal.fit_transform(x_train)\n",
    "    \n",
    "#fit the scaler from train portion to the test portion \n",
    "x_test_sc = std_scal.transform(x_test)\n",
    "\n",
    "\n",
    "##classifier models\n",
    "lrc2 = RidgeClassifier(alpha =0.2)\n",
    "gnb2 = GaussianNB()\n",
    "lgr2 = LogisticRegression(random_state = 0, C =10**4, max_iter = 500)\n",
    "svc2 = SVC(kernel = 'rbf', C =10, probability = True)  #why would you ever have it false? \n",
    "\n",
    "#tree-based classifiers\n",
    "rfc2 =  RandomForestClassifier(max_depth=10, random_state=0, n_estimators = 40)\n",
    "bc2 = BaggingClassifier(n_estimators  = 60, max_samples = 0.85)\n",
    "gbc2 = GradientBoostingClassifier(learning_rate =0.1, n_estimators = 40, max_depth =4 )\n",
    "xgbc2 = XGBClassifier(n_estimators= 45, eta=0.05)\n",
    "\n",
    "##quick checks \n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    model.fit(x_train_sc, y_train.ravel())\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test_sc)\n",
    "    y_predt= model.predict(x_train_sc)  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    acct = accuracy_score(y_train, y_predt)\n",
    "    f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], 'with tuning TEST: ', acc, f1, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eaeaeb99-763f-4885-b1a9-e6e83166f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, pr 20162017, tuned, TEST:  0.539622641509434 0.6291793313069909\n",
      "RidgeClassif 20162017, tuned, TEST:  0.4839622641509434 0.5939123979213066\n",
      "RandomForest 20162017, tuned, TEST:  0.5660377358490566 0.6904441453566622\n",
      "GaussianNB() 20162017, tuned, TEST:  0.5707547169811321 0.6291768541157293\n",
      "LogisticRegr 20162017, tuned, TEST:  0.44716981132075473 0.4904347826086956\n",
      "BaggingClass 20162017, tuned, TEST:  0.5367924528301887 0.6316579144786196\n",
      "GradientBoos 20162017, tuned, TEST:  0.5622641509433962 0.672316384180791\n",
      "XGBClassifie 20162017, tuned, TEST:  0.5716981132075472 0.6811797752808989\n"
     ]
    }
   ],
   "source": [
    "#check on 2016\n",
    "\n",
    "x_test2 = std_scal.transform(x_16).copy()\n",
    "y_test2 = y_16.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "#for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], '20162017, tuned, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7360dc39-f8c2-44bb-98db-cfd561bd6879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, pr 20172018, tuned, TEST:  0.5836501901140685 0.6857962697274033\n",
      "RidgeClassif 20172018, tuned, TEST:  0.5960076045627376 0.6975088967971531\n",
      "RandomForest 20172018, tuned, TEST:  0.5931558935361216 0.6857562408223201\n",
      "GaussianNB() 20172018, tuned, TEST:  0.5674904942965779 0.6211490424646129\n",
      "LogisticRegr 20172018, tuned, TEST:  0.5960076045627376 0.6992215145081387\n",
      "BaggingClass 20172018, tuned, TEST:  0.5484790874524715 0.6141348497156783\n",
      "GradientBoos 20172018, tuned, TEST:  0.5950570342205324 0.6921965317919075\n",
      "XGBClassifie 20172018, tuned, TEST:  0.5988593155893536 0.6901615271659325\n"
     ]
    }
   ],
   "source": [
    "#check on 2017\n",
    "\n",
    "x_test2 = std_scal.transform(x_17).copy()\n",
    "y_test2 = y_17.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "#for model in [svc, lrc, rfc, gnb, lgr, bc, gbc, xgbc]:\n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12],  '20172018, tuned, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbc0f2-6dff-4b02-9300-81ff3602e363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3ef2b-d5e5-4c64-9a59-37bec36ff938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb5e91-e1f2-4246-be3c-094c397a4f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28966856-2579-469a-aeaa-72f59b5be611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc38ca-eec8-40d8-a258-e2959bcaad15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d66b9ba-63ed-4767-9a36-01ec0e309e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's go with lgr, lgr2 (tuned or not) for betting investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47fbd718-57c1-4429-95fe-108dc66a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_16 = std_scal.transform(x_16).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ac5684d-7b01-42c6-b882-27e83e74e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52407527, 0.47592473],\n",
       "       [0.58086487, 0.41913513],\n",
       "       [0.41006043, 0.58993957],\n",
       "       ...,\n",
       "       [0.37652706, 0.62347294],\n",
       "       [0.44296909, 0.55703091],\n",
       "       [0.3999811 , 0.6000189 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc2.predict_proba(x_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "901e2652-3f6a-4cab-aec9-3dc441a37d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00380656, 0.32217664, 0.21205196, ..., 0.07010458, 0.54824593,\n",
       "       0.05309209])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba(x_16)[0:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4355c65a-6766-490a-bf4d-d4876b218902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55f4f1-e6c9-4913-840d-065449b6a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##make betting strategy on x_16 test it on x_17  ... and other seasons if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d88b104f-83f9-446a-9991-654258fa467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_proba(odds):\n",
    "    if odds > 0: \n",
    "        return 100/(odds+100)    #bet 100 to get 100+odds; profit = odds\n",
    "    if odds < 0:\n",
    "        return (-odds)/(-odds + 100)   #bet |odds| to get 100+|odds|; profit = 100\n",
    "    \n",
    "v_impl_proba = np.vectorize(implied_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "72f23f01-381a-412b-8068-4da280a4aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}  #x_16, lgr 0.55 ... Request rfc 0.58 x_16 and 0.6 on x_17 (later)\n",
    "\n",
    "dic['actual'] = [ x[0] for x in list(y_17)]\n",
    "dic['lgr_pred'] = list(rfc.predict(x_17))\n",
    "dic['lgr_conf_1'] = [round(x,4) for x in rfc.predict_proba(x_17)[0:, 1]]\n",
    "\n",
    "\n",
    "dic['lgr_conf_0'] =[round(x,4) for x in rfc.predict_proba(x_17)[0:, 0]]\n",
    "\n",
    "\n",
    "dic['away_odds'] = list(Y_17['away_odds'])\n",
    "dic['home_odds'] = list(Y_17['home_odds'])\n",
    "\n",
    "\n",
    "df_lgr = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "22b9faf0-d7a1-4cd2-88bc-4debbeb3c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}  #x_16, lgr 0.55 ... Request rfc 0.58 x_16 and 0.6 on x_17 (later)\n",
    "\n",
    "dic['actual'] = [ x[0] for x in list(y_16)]\n",
    "dic['lgr_pred'] = list(rfc.predict(x_16))\n",
    "dic['lgr_conf_1'] = [round(x,4) for x in rfc.predict_proba(x_16)[0:, 1]]\n",
    "\n",
    "\n",
    "dic['lgr_conf_0'] =[round(x,4) for x in rfc.predict_proba(x_16)[0:, 0]]\n",
    "\n",
    "\n",
    "dic['away_odds'] = list(Y_16['away_odds'])\n",
    "dic['home_odds'] = list(Y_16['home_odds'])\n",
    "\n",
    "\n",
    "df_lgr = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "73cc8997-cdc0-4ae5-9947-82481d57b6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['actual', 'lgr_pred', 'lgr_conf_1', 'lgr_conf_0', 'away_odds',\n",
       "       'home_odds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "9367a946-a1fd-4e6b-a5d8-86856a604142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgr['away_impl_proba'] = v_impl_proba(df_lgr['away_odds'])\n",
    "\n",
    "df_lgr['home_impl_proba'] = v_impl_proba(df_lgr['home_odds'])\n",
    "\n",
    "\n",
    "df_lgr['conf_1_sub_home_impl'] = df_lgr['lgr_conf_1'] - df_lgr['home_impl_proba']\n",
    "df_lgr['conf_0_sub_away_impl'] = df_lgr['lgr_conf_0'] - df_lgr['away_impl_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "fe9147d3-6c5d-4fba-9767-b48229bc8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgr = df_lgr.loc[:, ['actual', 'lgr_pred', 'lgr_conf_1', 'home_impl_proba',        'conf_1_sub_home_impl', 'conf_0_sub_away_impl',    'lgr_conf_0', 'away_impl_proba', \n",
    "'home_odds',  'away_odds']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2e2c62de-ff8f-4f38-8890-6f2be3e3d313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31      130.0\n",
       "54      165.0\n",
       "127    -160.0\n",
       "134     150.0\n",
       "358     118.0\n",
       "489     180.0\n",
       "545     130.0\n",
       "774    -165.0\n",
       "794     225.0\n",
       "818     215.0\n",
       "976    -265.0\n",
       "990    -235.0\n",
       "993    -275.0\n",
       "1017   -275.0\n",
       "1041    130.0\n",
       "Name: away_odds, dtype: float64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['away_odds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "3ea36517-39f9-47a4-8750-f4ba36f81738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lgr_pred</th>\n",
       "      <th>lgr_conf_1</th>\n",
       "      <th>home_impl_proba</th>\n",
       "      <th>conf_1_sub_home_impl</th>\n",
       "      <th>conf_0_sub_away_impl</th>\n",
       "      <th>lgr_conf_0</th>\n",
       "      <th>away_impl_proba</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "      <th>model_conf</th>\n",
       "      <th>bet_HA</th>\n",
       "      <th>bet</th>\n",
       "      <th>potential_ROI</th>\n",
       "      <th>pay_out</th>\n",
       "      <th>profit</th>\n",
       "      <th>cumul_profit</th>\n",
       "      <th>total_profit</th>\n",
       "      <th>total_bet</th>\n",
       "      <th>total_ROI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.0</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>8.320000e+02</td>\n",
       "      <td>832.0</td>\n",
       "      <td>8.320000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.674279</td>\n",
       "      <td>0.545259</td>\n",
       "      <td>0.570073</td>\n",
       "      <td>-0.024814</td>\n",
       "      <td>-0.012757</td>\n",
       "      <td>0.454741</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>-100.808894</td>\n",
       "      <td>51.542067</td>\n",
       "      <td>0.090517</td>\n",
       "      <td>0.674279</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.772520</td>\n",
       "      <td>101.777332</td>\n",
       "      <td>1.777332</td>\n",
       "      <td>850.240036</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494156</td>\n",
       "      <td>0.468926</td>\n",
       "      <td>0.092849</td>\n",
       "      <td>0.080177</td>\n",
       "      <td>0.081623</td>\n",
       "      <td>0.081914</td>\n",
       "      <td>0.092849</td>\n",
       "      <td>0.082110</td>\n",
       "      <td>116.945988</td>\n",
       "      <td>131.413516</td>\n",
       "      <td>0.185697</td>\n",
       "      <td>0.468926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259088</td>\n",
       "      <td>89.319910</td>\n",
       "      <td>89.319910</td>\n",
       "      <td>913.395565</td>\n",
       "      <td>7.962865e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.664948e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>-0.245457</td>\n",
       "      <td>-0.255537</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-370.000000</td>\n",
       "      <td>-235.000000</td>\n",
       "      <td>-0.246000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.270270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-936.750000</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473475</td>\n",
       "      <td>0.527743</td>\n",
       "      <td>-0.089163</td>\n",
       "      <td>-0.074996</td>\n",
       "      <td>0.382275</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-170.000000</td>\n",
       "      <td>-108.250000</td>\n",
       "      <td>-0.053050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>74.272500</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542450</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>-0.037332</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.457550</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>-138.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>976.345000</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617725</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.038971</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.526525</td>\n",
       "      <td>0.519806</td>\n",
       "      <td>-111.750000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.235450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>172.460000</td>\n",
       "      <td>72.460000</td>\n",
       "      <td>1438.437500</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.219256</td>\n",
       "      <td>0.217985</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>3376.510000</td>\n",
       "      <td>1.478740e+03</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>1.017773e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual    lgr_pred  lgr_conf_1  home_impl_proba  \\\n",
       "count  832.000000  832.000000  832.000000       832.000000   \n",
       "mean     0.578125    0.674279    0.545259         0.570073   \n",
       "std      0.494156    0.468926    0.092849         0.080177   \n",
       "min      0.000000    0.000000    0.377000         0.338983   \n",
       "25%      0.000000    0.000000    0.473475         0.527743   \n",
       "50%      1.000000    1.000000    0.542450         0.579832   \n",
       "75%      1.000000    1.000000    0.617725         0.629630   \n",
       "max      1.000000    1.000000    0.715600         0.787234   \n",
       "\n",
       "       conf_1_sub_home_impl  conf_0_sub_away_impl  lgr_conf_0  \\\n",
       "count            832.000000            832.000000  832.000000   \n",
       "mean              -0.024814             -0.012757    0.454741   \n",
       "std                0.081623              0.081914    0.092849   \n",
       "min               -0.245457             -0.255537    0.284400   \n",
       "25%               -0.089163             -0.074996    0.382275   \n",
       "50%               -0.037332              0.002752    0.457550   \n",
       "75%                0.038971              0.048214    0.526525   \n",
       "max                0.219256              0.217985    0.623000   \n",
       "\n",
       "       away_impl_proba   home_odds   away_odds  model_conf      bet_HA    bet  \\\n",
       "count       832.000000  832.000000  832.000000  832.000000  832.000000  832.0   \n",
       "mean          0.467498 -100.808894   51.542067    0.090517    0.674279  100.0   \n",
       "std           0.082110  116.945988  131.413516    0.185697    0.468926    0.0   \n",
       "min           0.250000 -370.000000 -235.000000   -0.246000    0.000000  100.0   \n",
       "25%           0.400000 -170.000000 -108.250000   -0.053050    0.000000  100.0   \n",
       "50%           0.458716 -138.000000  118.000000    0.084900    1.000000  100.0   \n",
       "75%           0.519806 -111.750000  150.000000    0.235450    1.000000  100.0   \n",
       "max           0.701493  195.000000  300.000000    0.431200    1.000000  100.0   \n",
       "\n",
       "       potential_ROI     pay_out      profit  cumul_profit  total_profit  \\\n",
       "count     832.000000  832.000000  832.000000    832.000000  8.320000e+02   \n",
       "mean        1.772520  101.777332    1.777332    850.240036  1.478740e+03   \n",
       "std         0.259088   89.319910   89.319910    913.395565  7.962865e-12   \n",
       "min         1.270270    0.000000 -100.000000   -936.750000  1.478740e+03   \n",
       "25%         1.588235    0.000000 -100.000000     74.272500  1.478740e+03   \n",
       "50%         1.714286  150.000000   50.000000    976.345000  1.478740e+03   \n",
       "75%         1.892857  172.460000   72.460000   1438.437500  1.478740e+03   \n",
       "max         2.850000  285.000000  185.000000   3376.510000  1.478740e+03   \n",
       "\n",
       "       total_bet     total_ROI  \n",
       "count      832.0  8.320000e+02  \n",
       "mean     83200.0  1.017773e+00  \n",
       "std          0.0  8.664948e-15  \n",
       "min      83200.0  1.017773e+00  \n",
       "25%      83200.0  1.017773e+00  \n",
       "50%      83200.0  1.017773e+00  \n",
       "75%      83200.0  1.017773e+00  \n",
       "max      83200.0  1.017773e+00  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "d66f5746-9046-409c-ab2b-d9bcc8439b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def find_pay_off(conf_1_at_least = 0 ,  conf_0_at_least =0 , diff_home_C_1_at_least =0, diff_away_C_0_at_least =0, type_bet = \"get_100\"  ): #or \"bet_100\"\n",
    "    #\n",
    "    ##return df with columns for each season in question:\n",
    "    #type_bet,  total_invested, total_earned, profit, ROI, \n",
    "    ##rows should be: avg for season in question let's do x_16 for now\n",
    "    dic = {}\n",
    "    dic['bet_strategy'] = type_bet\n",
    "    filter_thresh = ( df_lgr['lgr_conf_1'] >=  conf_1_at_least)| (df_lgr['lgr_conf_0'] >= conf_0_at_least)\n",
    "    filter_diff_thresh = (df_lgr['conf_1_sub_home_impl']  >= diff_home_C_1_at_least) | (df_lgr['conf_0_sub_away_impl']  >= diff_away_C_0_at_least)\n",
    "   \n",
    "    df = df_lgr[filter_thresh &  filter_diff_thresh].copy()\n",
    "    if type_bet == \"bet_100\":\n",
    "        pass\n",
    "    #assume type = \"get_100\"\n",
    "    #pred = df['lgr_pred'].copy\n",
    "    df['ones'] =1\n",
    "    df['non_pred'] = df['ones'] - df['lgr_pred']\n",
    "    df['model_conf'] = df_lgr['lgr_conf_1'] - df_lgr['lgr_conf_0']\n",
    "    df['bet_HA'] = df['lgr_pred']\n",
    "    df['bet'] = df['lgr_pred']*df['home_impl_proba'] + df['non_pred']*df['away_impl_proba']\n",
    "    df['bet'] = 100*df['bet']\n",
    "    df['bet'] = df['bet'].apply(lambda x: round(x,2))\n",
    "    df['potential_ROI'] = df['lgr_pred']*(1/df['home_impl_proba']) + df['non_pred']*(1/df['away_impl_proba'])\n",
    "    df['pay_out'] = df['actual']*100\n",
    "    df['profit'] = df['pay_out'] - df['bet']       \n",
    "    df['cumul_profit'] = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        df.loc[i, 'cumul_profit'] = df.loc[:i, 'profit'].sum()\n",
    "    df['total_profit'] = df['profit'].sum()    \n",
    "    df['total_bet'] = df['bet'].sum()    \n",
    "    df['total_ROI'] = df['total_profit']/df['total_bet']    \n",
    "    \n",
    "    df.drop(columns = ['ones', 'non_pred'], inplace = True)\n",
    "    return df\n",
    "\n",
    "def find_pay_off_bet_100(conf_1_at_least = 0 ,  conf_0_at_least =0 ,conf_thresh=0 , diff_home_C_1_at_least =0, diff_away_C_0_at_least =0, type_bet = \"Bet_100\"):  #or \"bet_100\"\n",
    "    #\n",
    "    ##return df with columns for each season in question:\n",
    "    #type_bet,  total_invested, total_earned, profit, ROI, \n",
    "    ##rows should be: avg for season in question let's do x_16 for now\n",
    "    dic = {}\n",
    "    dic['bet_strategy'] = type_bet\n",
    "    filter_thresh = (( df_lgr['lgr_conf_1'] >=  conf_1_at_least) + (df_lgr['lgr_conf_0'] >= conf_0_at_least)).copy()\n",
    "    filter_diff_thresh = ((df_lgr['conf_1_sub_home_impl']  >= diff_home_C_1_at_least) + (df_lgr['conf_0_sub_away_impl']  >= diff_away_C_0_at_least)).copy()\n",
    "    filter_conf_thresh = ((df_lgr['lgr_conf_1'] - df_lgr['lgr_conf_0']) > conf_thresh ).copy() \n",
    "   \n",
    "    df = df_lgr[ filter_diff_thresh & filter_conf_thresh].copy() \n",
    "    #df = df_lgr[ filter_diff_thresh & filter_thresh].copy() \n",
    "    \n",
    "    if type_bet == \"bet_100\":\n",
    "        pass\n",
    "    #assume type = \"get_100\"\n",
    "    #pred = df['lgr_pred'].copy\n",
    "    df['ones'] =1\n",
    "    df['non_pred'] = df['ones'] - df['lgr_pred']\n",
    "    df['model_conf'] = df_lgr['lgr_conf_1'] - df_lgr['lgr_conf_0']\n",
    "    df['bet_HA'] = df['lgr_pred']\n",
    "    \n",
    "    df['bet'] = 100\n",
    "    df['potential_ROI'] = df['lgr_pred']*(1/df['home_impl_proba']) + df['non_pred']*(1/df['away_impl_proba'])\n",
    "    df['pay_out'] = df['actual']*df['potential_ROI']*100\n",
    "    df['pay_out'] = df['pay_out'].apply(lambda x: round(x,2))\n",
    "    df['profit'] = df['pay_out'] - df['bet']                     \n",
    "    df['cumul_profit'] = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        df.loc[i, 'cumul_profit'] = df.loc[:i, 'profit'].sum()\n",
    "    df['total_profit'] = df['profit'].sum()    \n",
    "    df['total_bet'] = df['bet'].sum()    \n",
    "    df['total_ROI'] = (df['total_profit']+df['total_bet'])/df['total_bet']    \n",
    "    \n",
    "    df.drop(columns = ['ones', 'non_pred'], inplace = True)\n",
    "    return df\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "4d863656-eb1b-44a8-b05c-edf757a9d12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lgr_pred</th>\n",
       "      <th>lgr_conf_1</th>\n",
       "      <th>home_impl_proba</th>\n",
       "      <th>conf_1_sub_home_impl</th>\n",
       "      <th>conf_0_sub_away_impl</th>\n",
       "      <th>lgr_conf_0</th>\n",
       "      <th>away_impl_proba</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.09209</td>\n",
       "      <td>-0.13971</td>\n",
       "      <td>0.3841</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4192</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-0.10461</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.02539</td>\n",
       "      <td>-0.07301</td>\n",
       "      <td>0.4508</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-0.06331</td>\n",
       "      <td>0.01569</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-0.06951</td>\n",
       "      <td>0.02189</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-0.03241</td>\n",
       "      <td>-0.01521</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  lgr_pred  lgr_conf_1  home_impl_proba  conf_1_sub_home_impl  \\\n",
       "2       0.0       1.0      0.6159          0.52381               0.09209   \n",
       "97      1.0       0.0      0.4192          0.52381              -0.10461   \n",
       "115     1.0       1.0      0.5492          0.52381               0.02539   \n",
       "611     0.0       0.0      0.4605          0.52381              -0.06331   \n",
       "688     1.0       0.0      0.4543          0.52381              -0.06951   \n",
       "765     1.0       0.0      0.4914          0.52381              -0.03241   \n",
       "\n",
       "     conf_0_sub_away_impl  lgr_conf_0  away_impl_proba  home_odds  away_odds  \n",
       "2                -0.13971      0.3841          0.52381     -110.0     -110.0  \n",
       "97                0.05699      0.5808          0.52381     -110.0     -110.0  \n",
       "115              -0.07301      0.4508          0.52381     -110.0     -110.0  \n",
       "611               0.01569      0.5395          0.52381     -110.0     -110.0  \n",
       "688               0.02189      0.5457          0.52381     -110.0     -110.0  \n",
       "765              -0.01521      0.5086          0.52381     -110.0     -110.0  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgr.loc[df_lgr.loc[df_lgr['home_odds'] == df_lgr['away_odds'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "8c5654ad-7084-4513-8e6a-c10e39e6e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16606b43-1808-454c-b454-e9da2851b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_fav(x):\n",
    "    if x <0:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edc228-4d09-4fbf-8350-1478fbda7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##bet the spread mofo!\n",
    "\n",
    "def find_pay_off_spread(conf_1_at_least = 0 ,  conf_0_at_least =0 , diff_home_C_1_at_least =0, diff_away_C_0_at_least =0, type_bet = \"bet the spread!\"  ): #or \"bet_100\"\n",
    "    #\n",
    "    ##return df with columns for each season in question:\n",
    "    #type_bet,  total_invested, total_earned, profit, ROI, \n",
    "    ##rows should be: avg for season in question let's do x_16 for now\n",
    "    dic = {}\n",
    "    dic['bet_strategy'] = type_bet\n",
    "    filter_thresh = ( df_lgr['lgr_conf_1'] >=  conf_1_at_least)| (df_lgr['lgr_conf_0'] >= conf_0_at_least)\n",
    "    filter_diff_thresh = (df_lgr['conf_1_sub_home_impl']  >= diff_home_C_1_at_least) | (df_lgr['conf_0_sub_away_impl']  >= diff_away_C_0_at_least)\n",
    "   \n",
    "    #df = df_lgr[filter_thresh &  filter_diff_thresh].copy()\n",
    "    df = df_lgr.copy()\n",
    "    if type_bet == \"bet_100\":\n",
    "        pass\n",
    "    #assume type = \"get_100\"\n",
    "    #pred = df['lgr_pred'].copy\n",
    "\n",
    "    df['bet_HA'] = df['lgr_pred']\n",
    "    ##fir\n",
    "    \n",
    "    \n",
    "    df['bet'] = (1-df['lgr_pred'])*np.abs(df['away_odds']) + df['lgr_pred']*np.abs(df['home_odds'])\n",
    "    \n",
    " \n",
    "   \n",
    "    df['pay_out'] = (1-df['actual'])*(1-df['lgr_predict'])*np.abs(df['away_odds'])   +  df['actual']*df['lgr_predict']*df['lgr_pred']*np.abs(df['home_odds'])  \n",
    "    \n",
    "    df['profit'] = df['pay_out'] - df['bet']       \n",
    "    df['cumul_profit'] = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        df.loc[i, 'cumul_profit'] = df.loc[:i, 'profit'].sum()\n",
    "    df['total_profit'] = df['profit'].sum()    \n",
    "    df['total_bet'] = df['bet'].sum()    \n",
    "    df['total_ROI'] = df['total_profit']/df['total_bet']    \n",
    "    \n",
    "    df.drop(columns = ['ones', 'non_pred'], inplace = True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "031131b8-d3e1-4e34-94d7-61c548232495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247.64000000000016"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['profit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "1eb50768-9d59-4769-bd4b-33ad4c79ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['actual', 'lgr_pred', 'lgr_conf_1', 'home_impl_proba',\n",
    "       'conf_1_sub_home_impl', 'conf_0_sub_away_impl', \n",
    "       'away_impl_proba',  'bet_HA',\n",
    "       'bet', 'pay_out', 'profit', 'total_profit','cumul_profit', 'total_bet', 'total_ROI' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "eea8563b-baef-445a-8c70-c02dafec58ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 20)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "ef267937-9afb-476a-a39a-c8e2f02500b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lgr_pred</th>\n",
       "      <th>lgr_conf_1</th>\n",
       "      <th>home_impl_proba</th>\n",
       "      <th>conf_1_sub_home_impl</th>\n",
       "      <th>conf_0_sub_away_impl</th>\n",
       "      <th>away_impl_proba</th>\n",
       "      <th>bet_HA</th>\n",
       "      <th>bet</th>\n",
       "      <th>pay_out</th>\n",
       "      <th>profit</th>\n",
       "      <th>total_profit</th>\n",
       "      <th>cumul_profit</th>\n",
       "      <th>total_bet</th>\n",
       "      <th>total_ROI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.077143</td>\n",
       "      <td>-0.105664</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>157.14</td>\n",
       "      <td>57.14</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1243.16</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>154.05</td>\n",
       "      <td>54.05</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1297.21</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>-0.055428</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1197.21</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.061157</td>\n",
       "      <td>-0.094532</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>164.52</td>\n",
       "      <td>64.52</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1261.73</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5809</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.041729</td>\n",
       "      <td>-0.088289</td>\n",
       "      <td>0.507389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>185.47</td>\n",
       "      <td>85.47</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1347.20</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5981</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>-0.098870</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>143.48</td>\n",
       "      <td>43.48</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>984.31</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.086716</td>\n",
       "      <td>-0.133795</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>186.96</td>\n",
       "      <td>86.96</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1071.27</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>-0.105237</td>\n",
       "      <td>0.068956</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>971.27</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.619772</td>\n",
       "      <td>-0.103172</td>\n",
       "      <td>0.071877</td>\n",
       "      <td>0.411523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>161.35</td>\n",
       "      <td>61.35</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1032.62</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>-0.132966</td>\n",
       "      <td>0.102874</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>248.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>1478.74</td>\n",
       "      <td>1180.62</td>\n",
       "      <td>83200</td>\n",
       "      <td>1.017773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  lgr_pred  lgr_conf_1  home_impl_proba  conf_1_sub_home_impl  \\\n",
       "800     1.0       0.0      0.4693         0.392157              0.077143   \n",
       "801     1.0       1.0      0.5885         0.649123             -0.060623   \n",
       "802     0.0       1.0      0.7106         0.696970              0.013630   \n",
       "803     1.0       1.0      0.6690         0.607843              0.061157   \n",
       "804     1.0       1.0      0.5809         0.539171              0.041729   \n",
       "..      ...       ...         ...              ...                   ...   \n",
       "895     1.0       1.0      0.5981         0.696970             -0.098870   \n",
       "897     1.0       1.0      0.6216         0.534884              0.086716   \n",
       "898     0.0       0.0      0.4866         0.591837             -0.105237   \n",
       "899     1.0       1.0      0.5166         0.619772             -0.103172   \n",
       "900     1.0       0.0      0.4939         0.626866             -0.132966   \n",
       "\n",
       "     conf_0_sub_away_impl  away_impl_proba  bet_HA  bet  pay_out  profit  \\\n",
       "800             -0.105664         0.636364     0.0  100   157.14   57.14   \n",
       "801              0.034142         0.377358     1.0  100   154.05   54.05   \n",
       "802             -0.055428         0.344828     1.0  100     0.00 -100.00   \n",
       "803             -0.094532         0.425532     1.0  100   164.52   64.52   \n",
       "804             -0.088289         0.507389     1.0  100   185.47   85.47   \n",
       "..                    ...              ...     ...  ...      ...     ...   \n",
       "895              0.057072         0.344828     1.0  100   143.48   43.48   \n",
       "897             -0.133795         0.512195     1.0  100   186.96   86.96   \n",
       "898              0.068956         0.444444     0.0  100     0.00 -100.00   \n",
       "899              0.071877         0.411523     1.0  100   161.35   61.35   \n",
       "900              0.102874         0.403226     0.0  100   248.00  148.00   \n",
       "\n",
       "     total_profit  cumul_profit  total_bet  total_ROI  \n",
       "800       1478.74       1243.16      83200   1.017773  \n",
       "801       1478.74       1297.21      83200   1.017773  \n",
       "802       1478.74       1197.21      83200   1.017773  \n",
       "803       1478.74       1261.73      83200   1.017773  \n",
       "804       1478.74       1347.20      83200   1.017773  \n",
       "..            ...           ...        ...        ...  \n",
       "895       1478.74        984.31      83200   1.017773  \n",
       "897       1478.74       1071.27      83200   1.017773  \n",
       "898       1478.74        971.27      83200   1.017773  \n",
       "899       1478.74       1032.62      83200   1.017773  \n",
       "900       1478.74       1180.62      83200   1.017773  \n",
       "\n",
       "[75 rows x 15 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.loc[800:900,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d5670636-35ff-4cf9-b54f-75c0d985889f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-464-b49c3ed7f79e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-464-b49c3ed7f79e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_100 = find_pay_off_bet_100(conf_1_at_least = 0 ,  conf_0_at_least =0 ,conf_thresh=0 , diff_home_C_1_at_least =0, diff_away_C_0_at_least =0, type_bet = \"Bet_100\"):  #or \"bet_100\"\u001b[0m\n\u001b[0m                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_100 = find_pay_off_bet_100(conf_1_at_least = 0 ,  conf_0_at_least =0 ,conf_thresh=0 , diff_home_C_1_at_least =0, diff_away_C_0_at_least =0, type_bet = \"Bet_100\"):  #or \"bet_100\"\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "2312dce7-d990-43c2-a83e-dc018351d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31     -262.9\n",
       "54     -262.9\n",
       "134    -262.9\n",
       "358    -262.9\n",
       "489    -262.9\n",
       "545    -262.9\n",
       "774    -262.9\n",
       "794    -262.9\n",
       "818    -262.9\n",
       "1041   -262.9\n",
       "Name: total_profit, dtype: float64"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100 = find_pay_off_bet_100(conf_1_at_least = 0, conf_0_at_least = 0, conf_thresh = -100,diff_home_C_1_at_least =0.2, diff_away_C_0_at_least =0.1, type_bet = \"bet_100\"  )\n",
    "df_100['total_profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "0ba17d54-ec72-4077-9e50-80942ec15643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589622641509434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      -5111.77\n",
       "1      -5111.77\n",
       "2      -5111.77\n",
       "3      -5111.77\n",
       "4      -5111.77\n",
       "         ...   \n",
       "1055   -5111.77\n",
       "1056   -5111.77\n",
       "1057   -5111.77\n",
       "1058   -5111.77\n",
       "1059   -5111.77\n",
       "Name: total_profit, Length: 1060, dtype: float64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = find_pay_off(conf_1_at_least = 0.2,  conf_0_at_least = 0.2, diff_home_C_1_at_least = -10, diff_away_C_0_at_least = -10, type_bet = \"get_100\"  )\n",
    "print(accuracy_score(df['actual'], df['lgr_pred'], ))\n",
    "df['total_profit']                   #OR#                  #AND#                      ##OR##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8af7761b-d49f-4779-b270-058ea2534aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lgr_pred</th>\n",
       "      <th>lgr_conf_1</th>\n",
       "      <th>home_impl_proba</th>\n",
       "      <th>conf_1_sub_home_impl</th>\n",
       "      <th>conf_0_sub_away_impl</th>\n",
       "      <th>lgr_conf_0</th>\n",
       "      <th>away_impl_proba</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.546226</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.548657</td>\n",
       "      <td>0.572060</td>\n",
       "      <td>-0.023402</td>\n",
       "      <td>-0.014774</td>\n",
       "      <td>0.451343</td>\n",
       "      <td>0.466117</td>\n",
       "      <td>-101.160377</td>\n",
       "      <td>51.90566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498094</td>\n",
       "      <td>0.435908</td>\n",
       "      <td>0.071981</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>0.047763</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>0.071981</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>122.425390</td>\n",
       "      <td>134.58566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>-0.245919</td>\n",
       "      <td>-0.237642</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>-340.000000</td>\n",
       "      <td>-275.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499175</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>-0.055223</td>\n",
       "      <td>-0.044192</td>\n",
       "      <td>0.400075</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-170.000000</td>\n",
       "      <td>-111.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>-0.023808</td>\n",
       "      <td>-0.014130</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>-135.000000</td>\n",
       "      <td>115.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599925</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.500825</td>\n",
       "      <td>0.526066</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>150.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.206837</td>\n",
       "      <td>0.211357</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>270.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual     lgr_pred   lgr_conf_1  home_impl_proba  \\\n",
       "count  1060.000000  1060.000000  1060.000000      1060.000000   \n",
       "mean      0.546226     0.745283     0.548657         0.572060   \n",
       "std       0.498094     0.435908     0.071981         0.085215   \n",
       "min       0.000000     0.000000     0.395000         0.307692   \n",
       "25%       0.000000     0.000000     0.499175         0.521531   \n",
       "50%       1.000000     1.000000     0.549800         0.574468   \n",
       "75%       1.000000     1.000000     0.599925         0.629630   \n",
       "max       1.000000     1.000000     0.697900         0.772727   \n",
       "\n",
       "       conf_1_sub_home_impl  conf_0_sub_away_impl   lgr_conf_0  \\\n",
       "count           1060.000000           1060.000000  1060.000000   \n",
       "mean              -0.023402             -0.014774     0.451343   \n",
       "std                0.047763              0.048438     0.071981   \n",
       "min               -0.245919             -0.237642     0.302100   \n",
       "25%               -0.055223             -0.044192     0.400075   \n",
       "50%               -0.023808             -0.014130     0.450200   \n",
       "75%                0.004058              0.015623     0.500825   \n",
       "max                0.206837              0.211357     0.605000   \n",
       "\n",
       "       away_impl_proba    home_odds   away_odds  \n",
       "count      1060.000000  1060.000000  1060.00000  \n",
       "mean          0.466117  -101.160377    51.90566  \n",
       "std           0.086603   122.425390   134.58566  \n",
       "min           0.270270  -340.000000  -275.00000  \n",
       "25%           0.400000  -170.000000  -111.00000  \n",
       "50%           0.465116  -135.000000   115.00000  \n",
       "75%           0.526066  -109.000000   150.00000  \n",
       "max           0.733333   225.000000   270.00000  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "70331b72-1de4-48f8-9b58-6d3ae35c495c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589622641509434"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_lgr['actual'], df_lgr['lgr_pred'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "80be65f0-9a4e-4913-86e8-4a6f3e1fb01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit    11874.04\n",
      "dtype: float64 profit    308\n",
      "dtype: int64 avg loss  profit    108.936147\n",
      "dtype: float64\n",
      "profit   -12862.43\n",
      "dtype: float64 profit    216\n",
      "dtype: int64 avg loss  profit   -118.003945\n",
      "dtype: float64\n",
      "profit    3268.54\n",
      "dtype: float64 profit    75\n",
      "dtype: int64 avg loss  profit    29.986606\n",
      "dtype: float64\n",
      "profit   -6181.82\n",
      "dtype: float64 profit    109\n",
      "dtype: int64 avg loss  profit   -56.713945\n",
      "dtype: float64\n",
      "-3901.6700000000005\n",
      "avg loss -5.510833333333334\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[(df['bet_HA'] == 1)&(df['pay_out'] >0), ['profit']].sum(),\n",
    "df.loc[(df['bet_HA'] == 1)&(df['pay_out'] >0), ['profit']].count(),\n",
    "'avg loss ', df.loc[(df['bet_HA'] == 1)&(df['pay_out'] >0), ['profit']].sum()/df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].count()     )\n",
    "\n",
    "print(df.loc[(df['bet_HA'] == 1)&(df['pay_out'] ==0), ['profit']].sum(),\n",
    "df.loc[(df['bet_HA'] == 1)&(df['pay_out'] ==0), ['profit']].count(),\n",
    "'avg loss ', df.loc[(df['bet_HA'] == 1)&(df['pay_out'] ==0), ['profit']].sum()/df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].count()     )\n",
    "\n",
    "print(df.loc[(df['bet_HA'] == 0)&(df['pay_out'] >0), ['profit']].sum(),\n",
    "df.loc[(df['bet_HA'] == 0)&(df['pay_out'] >0), ['profit']].count(),\n",
    "'avg loss ', df.loc[(df['bet_HA'] == 0)&(df['pay_out'] >0), ['profit']].sum()/df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].count()     )\n",
    "\n",
    "print(df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].sum(),\n",
    "df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].count(),\n",
    "'avg loss ', df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].sum()/df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']].count()     )\n",
    "\n",
    "\n",
    "print(df['profit'].sum())\n",
    "print('avg loss', df['profit'].sum()/df['profit'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "fe64adc5-353a-44c3-947e-3e1629944d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profit    109\n",
       "dtype: int64"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[(df['bet_HA'] == 0)&(df['pay_out'] ==0), ['profit']] <0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "9c86a2bf-3638-4797-acfc-cc289c33fcb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-471-6cde86c145d1>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-471-6cde86c145d1>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    dic2'svc_proba'] = list(svc.predict_proba(x_16)[:,1])\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dic2['lgr_pred'] = list(lgr.predict(x_16))\n",
    "dic2['gnb_pred'] = list(gnb.predict(x_16))\n",
    "dic2'svc_proba'] = list(svc.predict_proba(x_16)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c3906d9c-f5cc-48bf-ac0d-394863c8b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[379,  70],\n",
       "       [500, 103]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When home team wins, classifier predicts they will win  17.08% of the time\n",
      "When home team loses, classifier predicts they will win  15.59% of the time\n",
      "When home team loses, classifier predicts they will lose  84.41% of the time\n",
      "When classifer predicts home team will win, home team actually wins  59.54% of the time\n",
      "When classifer predicts home team will lose, home team actually loses  43.12% of the time\n"
     ]
    }
   ],
   "source": [
    "predictions = gnb.predict(x_17)\n",
    "actual = y_17\n",
    "confusionMatrix = confusion_matrix(actual, predictions)\n",
    "display(confusionMatrix)\n",
    "\n",
    "tn = confusionMatrix[0][0]\n",
    "fp = confusionMatrix[0][1]\n",
    "fn = confusionMatrix[1][0]\n",
    "tp = confusionMatrix[1][1]\n",
    "actualYes = fn + tp \n",
    "actualNo = tn + fp\n",
    "predictedYes = fp + tp\n",
    "predictedNo = tn + fn\n",
    "\n",
    "print('When home team wins, classifier predicts they will win %6.2f%% of the time' % (tp / actualYes * 100))\n",
    "print('When home team loses, classifier predicts they will win %6.2f%% of the time' % (fp / actualNo * 100))\n",
    "print('When home team loses, classifier predicts they will lose %6.2f%% of the time' % (tn / actualNo * 100))\n",
    "print('When classifer predicts home team will win, home team actually wins %6.2f%% of the time' % (tp / predictedYes * 100))\n",
    "print('When classifer predicts home team will lose, home team actually loses %6.2f%% of the time' % (tn / predictedNo * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "eba2bf18-56b6-449d-90c4-1907eea18211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## is the betting and calcs being done correctly?  62% accuracy should easily have a profit ... \n",
    "\n",
    "\n",
    "##try all models\n",
    "\n",
    "##try regression \n",
    "\n",
    "##think about this \"confidence diff \" Leung mentioned \n",
    "\n",
    "\n",
    "\n",
    "##also ... sigh ... put in the FW% thing I guess ... [that was what I was struggling with calculating yesterday ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61739198-99b8-4f25-86bb-65c71b56239c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e68f63-887e-4982-aa16-591bbcaf6beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
